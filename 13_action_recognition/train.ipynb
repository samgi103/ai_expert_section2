{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"id":"SDRZ65LVt_mU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689922412848,"user_tz":-540,"elapsed":2495,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"118d2a07-c9c4-446e-d206-48f60db87476"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-07-21 06:53:30--  https://docs.google.com/uc?export=download&confirm=&id=1Br9F1os2dLkUqwIXwJjByzre2wXTez1W\n","Resolving docs.google.com (docs.google.com)... 173.194.194.101, 173.194.194.138, 173.194.194.102, ...\n","Connecting to docs.google.com (docs.google.com)|173.194.194.101|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://doc-0o-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ohg5q0jg3tu07g6cast3mhji6ljs18r6/1689922350000/05108294958722472523/*/1Br9F1os2dLkUqwIXwJjByzre2wXTez1W?e=download&uuid=9ea65e03-9066-45d8-9bb3-39892131fdbc [following]\n","Warning: wildcards not supported in HTTP.\n","--2023-07-21 06:53:31--  https://doc-0o-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ohg5q0jg3tu07g6cast3mhji6ljs18r6/1689922350000/05108294958722472523/*/1Br9F1os2dLkUqwIXwJjByzre2wXTez1W?e=download&uuid=9ea65e03-9066-45d8-9bb3-39892131fdbc\n","Resolving doc-0o-a8-docs.googleusercontent.com (doc-0o-a8-docs.googleusercontent.com)... 172.253.114.132, 2607:f8b0:4001:c22::84\n","Connecting to doc-0o-a8-docs.googleusercontent.com (doc-0o-a8-docs.googleusercontent.com)|172.253.114.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2408544 (2.3M) [application/octet-stream]\n","Saving to: ‘crop_mean.npy’\n","\n","crop_mean.npy       100%[===================>]   2.30M  --.-KB/s    in 0.02s   \n","\n","2023-07-21 06:53:31 (134 MB/s) - ‘crop_mean.npy’ saved [2408544/2408544]\n","\n","--2023-07-21 06:53:31--  https://docs.google.com/uc?export=download&confirm=&id=1BnU8a7l9tGxZN7wVpeCQx0CIgutW-742\n","Resolving docs.google.com (docs.google.com)... 173.194.194.101, 173.194.194.138, 173.194.194.102, ...\n","Connecting to docs.google.com (docs.google.com)|173.194.194.101|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://doc-0g-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/g752t67ckaaptcpchs9kuhllbbr2u5q9/1689922350000/05108294958722472523/*/1BnU8a7l9tGxZN7wVpeCQx0CIgutW-742?e=download&uuid=a5900ab9-3c02-401c-894d-d12d65fdbaca [following]\n","Warning: wildcards not supported in HTTP.\n","--2023-07-21 06:53:31--  https://doc-0g-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/g752t67ckaaptcpchs9kuhllbbr2u5q9/1689922350000/05108294958722472523/*/1BnU8a7l9tGxZN7wVpeCQx0CIgutW-742?e=download&uuid=a5900ab9-3c02-401c-894d-d12d65fdbaca\n","Resolving doc-0g-a8-docs.googleusercontent.com (doc-0g-a8-docs.googleusercontent.com)... 172.253.114.132, 2607:f8b0:4001:c22::84\n","Connecting to doc-0g-a8-docs.googleusercontent.com (doc-0g-a8-docs.googleusercontent.com)|172.253.114.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 116110 (113K) [application/octet-stream]\n","Saving to: ‘data_split.pkl’\n","\n","data_split.pkl      100%[===================>] 113.39K  --.-KB/s    in 0.002s  \n","\n","2023-07-21 06:53:31 (71.8 MB/s) - ‘data_split.pkl’ saved [116110/116110]\n","\n","--2023-07-21 06:53:32--  https://docs.google.com/uc?export=download&confirm=&id=1BQC3l22wya-sFYQMoUEYbmjhGZOYFZF-\n","Resolving docs.google.com (docs.google.com)... 173.194.194.101, 173.194.194.138, 173.194.194.102, ...\n","Connecting to docs.google.com (docs.google.com)|173.194.194.101|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://doc-10-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0uqjsht1bjshvb56kfij7hhsh0eiivaj/1689922350000/05108294958722472523/*/1BQC3l22wya-sFYQMoUEYbmjhGZOYFZF-?e=download&uuid=eeee6450-5cd7-4621-8158-e6226726ae8a [following]\n","Warning: wildcards not supported in HTTP.\n","--2023-07-21 06:53:32--  https://doc-10-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0uqjsht1bjshvb56kfij7hhsh0eiivaj/1689922350000/05108294958722472523/*/1BQC3l22wya-sFYQMoUEYbmjhGZOYFZF-?e=download&uuid=eeee6450-5cd7-4621-8158-e6226726ae8a\n","Resolving doc-10-a8-docs.googleusercontent.com (doc-10-a8-docs.googleusercontent.com)... 172.253.114.132, 2607:f8b0:4001:c22::84\n","Connecting to doc-10-a8-docs.googleusercontent.com (doc-10-a8-docs.googleusercontent.com)|172.253.114.132|:443... connected.\n","HTTP request sent, awaiting response... 429 Too Many Requests\n","2023-07-21 06:53:32 ERROR 429: Too Many Requests.\n","\n","\n","gzip: stdin: unexpected end of file\n","tar: Child returned status 1\n","tar: Error is not recoverable: exiting now\n"]}],"source":["!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Br9F1os2dLkUqwIXwJjByzre2wXTez1W' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Br9F1os2dLkUqwIXwJjByzre2wXTez1W\" -O crop_mean.npy && rm -rf ~/cookies.txt\n","!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1BnU8a7l9tGxZN7wVpeCQx0CIgutW-742' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1BnU8a7l9tGxZN7wVpeCQx0CIgutW-742\" -O data_split.pkl && rm -rf ~/cookies.txt\n","!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1BQC3l22wya-sFYQMoUEYbmjhGZOYFZF-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1BQC3l22wya-sFYQMoUEYbmjhGZOYFZF-\" -O dataset.tar.gz && rm -rf ~/cookies.txt\n","!tar -zxvf dataset.tar.gz"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"dtH0y5zQt_mV","executionInfo":{"status":"ok","timestamp":1689922417380,"user_tz":-540,"elapsed":257,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"outputs":[],"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import PIL.Image as Image\n","import random\n","import numpy as np\n","import os\n","import os.path\n","from os.path import join\n","import time\n","import pickle\n","import cv2\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.nn import functional as F\n","\n","#Run the code using selected GPU\n","os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1, 2, 3\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","TRAIN_CHECK_POINT = 'check_point/'\n","\n","#Experiment, Optimization options\n","DATA_SPLIT_PATH = 'data_split.pkl'\n","BATCH_SIZE = 10\n","# BATCH_SIZE = 3\n","NUM_CLASSES = 11\n","CROP_SIZE = 112\n","CHANNEL_NUM = 3\n","CLIP_LENGTH = 16\n","EPOCH_NUM = 50\n","LEARNING_RATE = 1e-4"]},{"cell_type":"markdown","metadata":{"id":"V21_zIL0t_mV"},"source":["## Data Processing : Define UCF11Dataset class"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"VAFk7tEHt_mW","executionInfo":{"status":"ok","timestamp":1689922420581,"user_tz":-540,"elapsed":255,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"outputs":[],"source":["# load video\n","# resize -> center crop --> normalize\n","CLIP_LENGTH = 16\n","\n","np_mean = np.load('crop_mean.npy').reshape([CLIP_LENGTH, 112, 112, 3])\n","\n","def get_test_num(filename):\n","    lines = open(filename, 'r')\n","    return len(list(lines))\n","\n","\n","def frame_process(clip, clip_length=CLIP_LENGTH, crop_size=112, channel_num=3):\n","    frames_num = len(clip)\n","    croped_frames = np.zeros([frames_num, crop_size, crop_size, channel_num]).astype(np.float32)\n","\n","    #Crop every frame into shape[crop_size, crop_size, channel_num]\n","    for i in range(frames_num):\n","        img = Image.fromarray(clip[i].astype(np.uint8))\n","        if img.width > img.height:\n","            scale = float(crop_size) / float(img.height)\n","            img = np.array(cv2.resize(np.array(img), (int(img.width * scale + 1), crop_size))).astype(np.float32)\n","        else:\n","            scale = float(crop_size) / float(img.width)\n","            img = np.array(cv2.resize(np.array(img), (crop_size, int(img.height * scale + 1)))).astype(np.float32)\n","        crop_x = int((img.shape[0] - crop_size) / 2)\n","        crop_y = int((img.shape[1] - crop_size) / 2)\n","        img = img[crop_x: crop_x + crop_size, crop_y : crop_y + crop_size, :]\n","        croped_frames[i, :, :, :] = img - np_mean[i]\n","\n","    return croped_frames\n","\n","\n","def convert_images_to_clip(filename, clip_length=CLIP_LENGTH, crop_size=112, channel_num=3):\n","    clip = []\n","    for parent, dirnames, filenames in os.walk(filename):\n","        filenames = sorted(filenames)\n","        if len(filenames) < clip_length:\n","            for i in range(0, len(filenames)):\n","                image_name = str(filename) + '/' + str(filenames[i])\n","                img = Image.open(image_name)\n","                img_data = np.array(img)\n","                clip.append(img_data)\n","            for i in range(clip_length - len(filenames)):\n","                image_name = str(filename) + '/' + str(filenames[len(filenames) - 1])\n","                img = Image.open(image_name)\n","                img_data = np.array(img)\n","                clip.append(img_data)\n","        else:\n","            # In the case that the length of the video is longer than the pre-defined CLIP_LENGTH (=16)\n","            # Randomly pick 16 consecutive frames and merge them as a clip\n","            s_index = random.randint(0, len(filenames) - clip_length)\n","            for i in range(s_index, s_index + clip_length):\n","              image_name = str(filename) + '/' + str(filenames[i])\n","              img = Image.open(image_name)\n","              img_data = np.array(img)\n","              clip.append(img_data)\n","\n","\n","\n","\n","    if len(clip) == 0:\n","        print(filename)\n","    clip = frame_process(clip, clip_length, crop_size, channel_num)\n","    return clip # shape: [clip_length, crop_size, crop_size, channel_num]\n","\n","class UCF11Dataset(Dataset):\n","    def __init__(self, data_list, num_classes, crop_size=112, channel_num=3):\n","        self.data_list = data_list\n","        self.video_list = list(data_list)\n","        self.crop_size = crop_size\n","        self.channel_num = channel_num\n","        self.num_classes = num_classes\n","\n","    def __len__(self):\n","        return len(self.video_list)\n","\n","    def __getitem__(self, i):\n","        line = self.video_list[i].strip('\\n').split()\n","        dirname = line[0]\n","        label = int(self.data_list[dirname])\n","        clips = convert_images_to_clip(dirname, CLIP_LENGTH, self.crop_size, self.channel_num)\n","\n","        clips = np.transpose(np.array(clips).astype(np.float32), (3, 0, 1, 2))\n","\n","        batch_data = {'clips': clips, 'labels': label}\n","\n","        return batch_data"]},{"cell_type":"markdown","metadata":{"id":"rnKD954Ct_mX"},"source":["## Load UCF11(UCF YouTube Action) Dataset Path"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"2b0RRXw1t_mX","executionInfo":{"status":"ok","timestamp":1689922423742,"user_tz":-540,"elapsed":406,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"outputs":[],"source":["DATA_SPLIT_PATH = 'data_split.pkl'\n","ucf11_dataset = pickle.load(open(DATA_SPLIT_PATH,'rb'))\n","train_set = ucf11_dataset['train']\n","test_set = ucf11_dataset['test']"]},{"cell_type":"markdown","metadata":{"id":"u5SEsOt_t_mX"},"source":["## Set Dataset and Dataloader"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"xaNEnVVdt_mY","executionInfo":{"status":"ok","timestamp":1689922425059,"user_tz":-540,"elapsed":249,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"outputs":[],"source":["train_video_dataset = UCF11Dataset(train_set, NUM_CLASSES)\n","test_video_dataset = UCF11Dataset(test_set, NUM_CLASSES)\n","\n","train_video_dataloader = DataLoader(train_video_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","test_video_dataloader = DataLoader(test_video_dataset, batch_size = BATCH_SIZE, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"Fnj9nAsWt_mY"},"source":["## Define NonLocal Block"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"A887cG7Xt_mY","executionInfo":{"status":"ok","timestamp":1689922426617,"user_tz":-540,"elapsed":255,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"outputs":[],"source":["class NonLocalBlock3D(nn.Module):\n","    def __init__(self, in_channels, test_mode=False, dimension=3, sub_sample=True):\n","        super(NonLocalBlock3D, self).__init__()\n","\n","        self.test_mode = test_mode\n","        self.dimension = dimension\n","        self.sub_sample = sub_sample\n","\n","        self.in_channels = in_channels\n","\n","        self.inter_channels = in_channels // 2\n","        if self.inter_channels == 0:\n","            self.inter_channels = 1\n","\n","        max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n","\n","        #============================================================\n","        #make self.g , self.theta, self.phi\n","        #these are nn.Conv3d, 1x1x1, stride=1, padding=0\n","        #============================================================\n","        # self.g =\n","\n","        # self.theta =\n","\n","        # self.phi =\n","\n","        # self.g = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\n","        # self.theta = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\n","        # self.phi = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\n","        self.g = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n","                         kernel_size=1, stride=1, padding=0)\n","\n","        self.theta = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n","                             kernel_size=1, stride=1, padding=0)\n","\n","        self.phi = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n","                           kernel_size=1, stride=1, padding=0)\n","        #============================================================\n","\n","        #============================================================\n","        #make self.W\n","        #in this part, self.W.weight and self.W.bias must initialize to 0\n","        #============================================================\n","        # self.W =\n","        # self.W = nn.Conv3d(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1, stride=1, padding=0)\n","        self.W = nn.Conv3d(in_channels=self.inter_channels, out_channels=self.in_channels,\n","                         kernel_size=1, stride=1, padding=0)\n","\n","        nn.init.constant_(self.W.weight, 0)\n","        nn.init.constant_(self.W.bias, 0)\n","        #============================================================\n","\n","        if sub_sample:\n","            self.g = nn.Sequential(self.g, max_pool_layer)\n","            self.phi = nn.Sequential(self.phi, max_pool_layer)\n","\n","    def forward(self, x):\n","        '''\n","        :param x: (b, c, t, h, w)\n","        :return:\n","        '''\n","        batch_size = x.size(0)\n","        #============================================================\n","        #1. use self.g(x)\n","        #2. use self.theta(x)\n","        #3. use self.phi(x)\n","        #4. several matrix multiplication between previous return value\n","        #5. use self.W(y)\n","        #6. make z with x and self.W(y)\n","        #============================================================\n","        # # g_x =\n","        # g_x = g_x.view(batch_size, self.inter_channels, -1)\n","        # g_x = g_x.permute(0, 2, 1)\n","\n","        # # theta_x =\n","        # theta_x = theta_x.view(batch_size, self.inter_channels, -1)\n","        # theta_x = theta_x.permute(0, 2, 1)\n","\n","        # # phi_x =\n","        # phi_x = phi_x.view(batch_size, self.inter_channels, -1)\n","\n","        # # f =\n","        # # f_div_C =\n","        # f = torch.matmul(theta_x, phi_x)\n","        # f_div_C = F.softmax(f, dim=-1)\n","\n","        # # y =\n","        # y = torch.matmul(f_div_C, g_x)\n","        # y = y.permute(0, 2, 1).contiguous()\n","        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n","        g_x = g_x.permute(0, 2, 1)\n","\n","        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n","        theta_x = theta_x.permute(0, 2, 1)\n","\n","        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n","\n","        f = torch.matmul(theta_x, phi_x)  # B X THW X THW\n","        f_div_C = F.softmax(f, dim=-1)    # B X THW X THW\n","\n","        y = torch.matmul(f_div_C, g_x)\n","\n","        if self.test_mode:\n","            print(\"x: {}\".format(x.shape))\n","            print(\"g_x: {}\".format(g_x.shape))\n","            print(\"theta_x: {}\".format(theta_x.shape))\n","            print(\"phi_x: {}\".format(phi_x.shape))\n","            print(\"f: {}\".format(f.shape))\n","            print(\"y: {}\".format(y.shape))\n","\n","        y = y.permute(0, 2, 1).contiguous()\n","        # y =\n","        # W_y =\n","        # z =\n","        # y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n","        # W_y = self.W(y)\n","        # z = W_y + x\n","        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n","        W_y = self.W(y)\n","        z = W_y + x\n","        #============================================================\n","\n","        return z"]},{"cell_type":"markdown","metadata":{"id":"QP2RtrGyt_mY"},"source":["## Define C3D Network"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"hUd_TD1Vt_mY","executionInfo":{"status":"ok","timestamp":1689923188100,"user_tz":-540,"elapsed":327,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"outputs":[],"source":["class C3D(nn.Module):\n","    \"\"\"\n","    The C3D network.\n","    \"\"\"\n","\n","    def __init__(self, num_classes, pretrained=\"\"):\n","        super(C3D, self).__init__()\n","\n","        #============================================================\n","        #All of convolution layers use kernel_size (3,3,3) and padding (1, 1, 1)\n","        #conv1 3 -> 64\n","        #conv2 64 -> 128\n","        #conv3a 128 -> 256\n","        #conv3b 256 -> 256\n","        #conv4a 256 -> 512\n","        #conv4b 512 -> 512\n","        #conv5a 512 -> 512\n","        #conv5b 512 -> 512\n","        #fc6 (you need to find input channel size) -> 4096\n","        #fc7 4096 -> num_classes\n","        #============================================================\n","        # B X C X 16 X 112 X 112\n","        # self.conv1 =\n","        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3,3,3), padding = (1, 1, 1))\n","        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n","        self.nonlocal1 = NonLocalBlock3D(64)\n","\n","        # B X C X 16 X 56 X 56\n","        # self.conv2 =\n","        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3,3,3), padding=(1,1,1))\n","        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n","        self.nonlocal2 = NonLocalBlock3D(128)\n","\n","\n","        # self.conv3a =\n","        # self.conv3b =\n","        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3,3,3), padding=(1,1,1))\n","        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3,3,3), padding=(1,1,1))\n","        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n","        self.nonlocal3 = NonLocalBlock3D(256)\n","\n","        # self.conv4a =\n","        # self.conv4b =\n","        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3,3,3), padding=(1,1,1))\n","        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3,3,3), padding=(1,1,1))\n","        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n","        self.nonlocal4 = NonLocalBlock3D(512)\n","\n","        # self.conv5a =\n","        # self.conv5b =\n","        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3,3,3), padding=(1,1,1))\n","        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3,3,3), padding=(1,1,1))\n","        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n","\n","        # self.fc6 =\n","        # self.fc7 =\n","        # 512 X 1 X 4 X 4\n","        self.fc6 = nn.Linear(8192, 4096)\n","        self.fc7 = nn.Linear(4096, num_classes)\n","        #============================================================\n","\n","        self.dropout = nn.Dropout(p=0.5)\n","\n","        self.relu = nn.ReLU()\n","\n","        self.__init_weight()\n","\n","        if pretrained:\n","            self.__load_pretrained_weights(pretrained)\n","\n","    def forward(self, x):\n","\n","        #============================================================\n","        #use all layer to forward\n","        #============================================================\n","        # conv --> relu --> pool --> nonlocal\n","        # 주장 하는 바에 의하면 nonlocal을 썼을때 성능이 올라야 하는게 맞는데\n","        # 실제로 써보니 효과가 없어서 뺌(그리고 GPU가 터짐)\n","        x = self.relu(self.conv1(x))\n","        x = self.pool1(x)\n","        # x = self.nonlocal1(x)\n","\n","        x = self.relu(self.conv2(x))\n","        x = self.pool2(x)\n","        # x = self.nonlocal2(x)\n","\n","        x = self.relu(self.conv3a(x))\n","        x = self.relu(self.conv3b(x))\n","        x = self.pool3(x)\n","        # x = self.nonlocal3(x)\n","\n","        x = self.relu(self.conv4a(x))\n","        x = self.relu(self.conv4b(x))\n","        x = self.pool4(x)\n","        # x = self.nonlocal4(x)\n","\n","        x = self.relu(self.conv5a(x))\n","        x = self.relu(self.conv5b(x))\n","        x = self.pool5(x)\n","\n","        x = x.view(-1, 8192)\n","        x = self.relu(self.fc6(x))\n","        x = self.dropout(x)\n","\n","        #============================================================\n","\n","        logits = self.fc7(x)\n","\n","        return logits\n","\n","    def __load_pretrained_weights(self, model_path):\n","        \"\"\"Initialiaze network.\"\"\"\n","        corresp_name = {\n","                        # Conv1\n","                        \"features.0.weight\": \"conv1.weight\",\n","                        \"features.0.bias\": \"conv1.bias\",\n","                        # Conv2\n","                        \"features.3.weight\": \"conv2.weight\",\n","                        \"features.3.bias\": \"conv2.bias\",\n","                        # Conv3a\n","                        \"features.6.weight\": \"conv3a.weight\",\n","                        \"features.6.bias\": \"conv3a.bias\",\n","                        # Conv3b\n","                        \"features.8.weight\": \"conv3b.weight\",\n","                        \"features.8.bias\": \"conv3b.bias\",\n","                        # Conv4a\n","                        \"features.11.weight\": \"conv4a.weight\",\n","                        \"features.11.bias\": \"conv4a.bias\",\n","                        # Conv4b\n","                        \"features.13.weight\": \"conv4b.weight\",\n","                        \"features.13.bias\": \"conv4b.bias\",\n","                        # Conv5a\n","                        \"features.16.weight\": \"conv5a.weight\",\n","                        \"features.16.bias\": \"conv5a.bias\",\n","                         # Conv5b\n","                        \"features.18.weight\": \"conv5b.weight\",\n","                        \"features.18.bias\": \"conv5b.bias\",\n","                        # fc6\n","                        \"classifier.0.weight\": \"fc6.weight\",\n","                        \"classifier.0.bias\": \"fc6.bias\",\n","                        # fc7\n","                        \"classifier.3.weight\": \"fc7.weight\",\n","                        \"classifier.3.bias\": \"fc7.bias\",\n","                        }\n","\n","        p_dict = torch.load(model_path)['state_dict']\n","        s_dict = self.state_dict()\n","        for name in p_dict:\n","            if name not in corresp_name:\n","                continue\n","            s_dict[corresp_name[name]] = p_dict[name]\n","        self.load_state_dict(s_dict)\n","\n","    def __init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv3d):\n","                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                # m.weight.data.normal_(0, math.sqrt(2. / n))\n","                torch.nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm3d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()"]},{"cell_type":"markdown","metadata":{"id":"kAksRlGHt_mZ"},"source":["## Set Network and Optimizer"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Xy605coot_mZ","executionInfo":{"status":"ok","timestamp":1689923196331,"user_tz":-540,"elapsed":1424,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"outputs":[],"source":["net = C3D(num_classes=NUM_CLASSES)\n","net = net.cuda()\n","\n","#net = C3D(num_classes=NUM_CLASSES).cuda()\n","#net = torch.nn.DataParallel(net).to(device)\n","\n","optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"markdown","metadata":{"id":"exfCXczpt_mZ"},"source":["## Train and Test C3D"]},{"cell_type":"code","execution_count":24,"metadata":{"tags":[],"id":"7OIQtRvst_mZ","outputId":"141cfa4b-3127-45c7-e823-4a4908d87fd5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689928892363,"user_tz":-540,"elapsed":5693709,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Batch 0: Loss is 75.14204; Accuracy is 0.00000\n","Epoch 1, Batch 10: Loss is 8.25124; Accuracy is 0.00000\n","Epoch 1, Batch 20: Loss is 5.78204; Accuracy is 0.00000\n","Epoch 1, Batch 30: Loss is 2.56813; Accuracy is 0.00000\n","Epoch 1, Batch 40: Loss is 2.51896; Accuracy is 0.00000\n","Epoch 1, Batch 50: Loss is 2.70985; Accuracy is 0.00000\n","Epoch 1, Batch 60: Loss is 2.72598; Accuracy is 0.00000\n","Epoch 1, Batch 70: Loss is 2.18737; Accuracy is 0.00000\n","Epoch 1, Batch 80: Loss is 2.24310; Accuracy is 0.00000\n","Epoch 1, Batch 90: Loss is 2.08680; Accuracy is 0.00000\n","Epoch 1, Batch 100: Loss is 2.75199; Accuracy is 0.00000\n","Epoch 1, Batch 110: Loss is 2.18645; Accuracy is 0.00000\n","Epoch 1, Batch 120: Loss is 2.16158; Accuracy is 0.33333\n","Epoch 1, Batch 130: Loss is 2.06592; Accuracy is 0.66667\n","Epoch 1, Batch 140: Loss is 2.28161; Accuracy is 0.00000\n","Epoch 1, Batch 150: Loss is 2.24912; Accuracy is 0.33333\n","Epoch 1, Batch 160: Loss is 2.01088; Accuracy is 0.33333\n","Epoch 1, Batch 170: Loss is 2.59865; Accuracy is 0.00000\n","Epoch 1, Batch 180: Loss is 2.38623; Accuracy is 0.00000\n","Epoch 1, Batch 190: Loss is 2.07311; Accuracy is 0.33333\n","Epoch 1, Batch 200: Loss is 2.48363; Accuracy is 0.00000\n","Epoch 1, Batch 210: Loss is 1.94582; Accuracy is 0.33333\n","Epoch 1, Batch 220: Loss is 2.31284; Accuracy is 0.33333\n","Epoch 1, Batch 230: Loss is 1.83793; Accuracy is 0.66667\n","Epoch 1, Batch 240: Loss is 2.58522; Accuracy is 0.00000\n","Epoch 1, Batch 250: Loss is 2.64845; Accuracy is 0.00000\n","Epoch 1, Batch 260: Loss is 1.93795; Accuracy is 0.33333\n","Epoch 1, Batch 270: Loss is 2.21096; Accuracy is 0.00000\n","Epoch 1, Batch 280: Loss is 3.21299; Accuracy is 0.00000\n","Epoch 1, Batch 290: Loss is 2.20468; Accuracy is 0.33333\n","Epoch 1, Batch 300: Loss is 2.17830; Accuracy is 0.00000\n","Epoch 1, Batch 310: Loss is 1.86542; Accuracy is 0.33333\n","Epoch 1, Batch 320: Loss is 2.02050; Accuracy is 0.00000\n","Epoch 1, Batch 330: Loss is 2.15446; Accuracy is 0.00000\n","Epoch 1, Batch 340: Loss is 2.23909; Accuracy is 0.33333\n","Epoch 1, Batch 350: Loss is 2.32907; Accuracy is 0.33333\n","Epoch 1, Batch 360: Loss is 1.73815; Accuracy is 0.33333\n","Epoch 1, Batch 370: Loss is 1.21165; Accuracy is 0.33333\n","Epoch 1, Batch 380: Loss is 2.00445; Accuracy is 0.00000\n","Epoch 1: Average loss is: 5.40489; Average accuracy is: 0.20210\n","Test loss is 2.13651; Accuracy is 0.26250\n","Epoch 2, Batch 0: Loss is 2.41703; Accuracy is 0.00000\n","Epoch 2, Batch 10: Loss is 2.19556; Accuracy is 0.00000\n","Epoch 2, Batch 20: Loss is 2.41028; Accuracy is 0.00000\n","Epoch 2, Batch 30: Loss is 2.04555; Accuracy is 0.00000\n","Epoch 2, Batch 40: Loss is 1.51190; Accuracy is 0.00000\n","Epoch 2, Batch 50: Loss is 1.09743; Accuracy is 0.33333\n","Epoch 2, Batch 60: Loss is 2.26895; Accuracy is 0.33333\n","Epoch 2, Batch 70: Loss is 1.97744; Accuracy is 0.66667\n","Epoch 2, Batch 80: Loss is 2.00610; Accuracy is 0.00000\n","Epoch 2, Batch 90: Loss is 1.89014; Accuracy is 0.33333\n","Epoch 2, Batch 100: Loss is 0.98228; Accuracy is 0.66667\n","Epoch 2, Batch 110: Loss is 1.71965; Accuracy is 0.33333\n","Epoch 2, Batch 120: Loss is 2.38940; Accuracy is 0.00000\n","Epoch 2, Batch 130: Loss is 1.84064; Accuracy is 0.66667\n","Epoch 2, Batch 140: Loss is 1.53242; Accuracy is 1.00000\n","Epoch 2, Batch 150: Loss is 1.86281; Accuracy is 0.33333\n","Epoch 2, Batch 160: Loss is 1.75459; Accuracy is 0.33333\n","Epoch 2, Batch 170: Loss is 2.16965; Accuracy is 0.00000\n","Epoch 2, Batch 180: Loss is 1.61050; Accuracy is 0.66667\n","Epoch 2, Batch 190: Loss is 1.45092; Accuracy is 0.66667\n","Epoch 2, Batch 200: Loss is 0.68321; Accuracy is 1.00000\n","Epoch 2, Batch 210: Loss is 1.08793; Accuracy is 0.66667\n","Epoch 2, Batch 220: Loss is 2.01681; Accuracy is 0.00000\n","Epoch 2, Batch 230: Loss is 1.55923; Accuracy is 0.33333\n","Epoch 2, Batch 240: Loss is 2.07019; Accuracy is 0.66667\n","Epoch 2, Batch 250: Loss is 2.58185; Accuracy is 0.00000\n","Epoch 2, Batch 260: Loss is 1.72004; Accuracy is 0.66667\n","Epoch 2, Batch 270: Loss is 0.45674; Accuracy is 1.00000\n","Epoch 2, Batch 280: Loss is 1.15886; Accuracy is 0.33333\n","Epoch 2, Batch 290: Loss is 4.20795; Accuracy is 0.00000\n","Epoch 2, Batch 300: Loss is 1.00608; Accuracy is 0.66667\n","Epoch 2, Batch 310: Loss is 1.81545; Accuracy is 0.66667\n","Epoch 2, Batch 320: Loss is 1.19357; Accuracy is 0.33333\n","Epoch 2, Batch 330: Loss is 2.16572; Accuracy is 0.33333\n","Epoch 2, Batch 340: Loss is 1.27751; Accuracy is 0.33333\n","Epoch 2, Batch 350: Loss is 1.22675; Accuracy is 0.33333\n","Epoch 2, Batch 360: Loss is 4.87057; Accuracy is 0.33333\n","Epoch 2, Batch 370: Loss is 1.51911; Accuracy is 0.33333\n","Epoch 2, Batch 380: Loss is 2.13969; Accuracy is 0.00000\n","Epoch 2: Average loss is: 1.86037; Average accuracy is: 0.36220\n","Test loss is 2.11493; Accuracy is 0.35313\n","Epoch 3, Batch 0: Loss is 1.95503; Accuracy is 0.33333\n","Epoch 3, Batch 10: Loss is 1.66754; Accuracy is 0.33333\n","Epoch 3, Batch 20: Loss is 0.58676; Accuracy is 1.00000\n","Epoch 3, Batch 30: Loss is 1.99250; Accuracy is 0.33333\n","Epoch 3, Batch 40: Loss is 1.06160; Accuracy is 0.66667\n","Epoch 3, Batch 50: Loss is 2.08099; Accuracy is 0.33333\n","Epoch 3, Batch 60: Loss is 3.79669; Accuracy is 0.00000\n","Epoch 3, Batch 70: Loss is 2.47202; Accuracy is 0.00000\n","Epoch 3, Batch 80: Loss is 1.65521; Accuracy is 0.33333\n","Epoch 3, Batch 90: Loss is 1.32442; Accuracy is 0.33333\n","Epoch 3, Batch 100: Loss is 2.62285; Accuracy is 0.00000\n","Epoch 3, Batch 110: Loss is 1.85662; Accuracy is 0.66667\n","Epoch 3, Batch 120: Loss is 1.64865; Accuracy is 0.33333\n","Epoch 3, Batch 130: Loss is 1.58392; Accuracy is 0.33333\n","Epoch 3, Batch 140: Loss is 2.80121; Accuracy is 0.33333\n","Epoch 3, Batch 150: Loss is 2.03084; Accuracy is 0.33333\n","Epoch 3, Batch 160: Loss is 2.10168; Accuracy is 0.33333\n","Epoch 3, Batch 170: Loss is 0.48418; Accuracy is 1.00000\n","Epoch 3, Batch 180: Loss is 2.35372; Accuracy is 0.00000\n","Epoch 3, Batch 190: Loss is 1.37465; Accuracy is 0.33333\n","Epoch 3, Batch 200: Loss is 1.43818; Accuracy is 0.33333\n","Epoch 3, Batch 210: Loss is 0.89876; Accuracy is 0.33333\n","Epoch 3, Batch 220: Loss is 2.16227; Accuracy is 0.33333\n","Epoch 3, Batch 230: Loss is 2.42744; Accuracy is 0.66667\n","Epoch 3, Batch 240: Loss is 1.71601; Accuracy is 0.33333\n","Epoch 3, Batch 250: Loss is 1.77299; Accuracy is 0.66667\n","Epoch 3, Batch 260: Loss is 1.56473; Accuracy is 0.33333\n","Epoch 3, Batch 270: Loss is 1.58152; Accuracy is 0.33333\n","Epoch 3, Batch 280: Loss is 1.36069; Accuracy is 0.33333\n","Epoch 3, Batch 290: Loss is 0.71039; Accuracy is 0.66667\n","Epoch 3, Batch 300: Loss is 1.69718; Accuracy is 0.00000\n","Epoch 3, Batch 310: Loss is 2.83073; Accuracy is 0.33333\n","Epoch 3, Batch 320: Loss is 1.11387; Accuracy is 0.66667\n","Epoch 3, Batch 330: Loss is 0.85837; Accuracy is 0.66667\n","Epoch 3, Batch 340: Loss is 4.14333; Accuracy is 0.00000\n","Epoch 3, Batch 350: Loss is 1.83772; Accuracy is 0.33333\n","Epoch 3, Batch 360: Loss is 2.17005; Accuracy is 0.66667\n","Epoch 3, Batch 370: Loss is 1.59084; Accuracy is 0.66667\n","Epoch 3, Batch 380: Loss is 1.53873; Accuracy is 0.66667\n","Epoch 3: Average loss is: 1.66745; Average accuracy is: 0.43920\n","Test loss is 1.98838; Accuracy is 0.39375\n","Epoch 4, Batch 0: Loss is 1.23703; Accuracy is 0.66667\n","Epoch 4, Batch 10: Loss is 0.60575; Accuracy is 1.00000\n","Epoch 4, Batch 20: Loss is 1.20588; Accuracy is 0.66667\n","Epoch 4, Batch 30: Loss is 0.62004; Accuracy is 1.00000\n","Epoch 4, Batch 40: Loss is 1.58177; Accuracy is 0.33333\n","Epoch 4, Batch 50: Loss is 0.80777; Accuracy is 1.00000\n","Epoch 4, Batch 60: Loss is 1.22203; Accuracy is 0.33333\n","Epoch 4, Batch 70: Loss is 1.92894; Accuracy is 0.33333\n","Epoch 4, Batch 80: Loss is 2.57881; Accuracy is 0.00000\n","Epoch 4, Batch 90: Loss is 1.55299; Accuracy is 0.66667\n","Epoch 4, Batch 100: Loss is 2.49681; Accuracy is 0.33333\n","Epoch 4, Batch 110: Loss is 1.64736; Accuracy is 0.33333\n","Epoch 4, Batch 120: Loss is 2.37445; Accuracy is 0.00000\n","Epoch 4, Batch 130: Loss is 1.31708; Accuracy is 0.66667\n","Epoch 4, Batch 140: Loss is 1.64070; Accuracy is 0.66667\n","Epoch 4, Batch 150: Loss is 1.58408; Accuracy is 0.33333\n","Epoch 4, Batch 160: Loss is 1.55479; Accuracy is 0.33333\n","Epoch 4, Batch 170: Loss is 1.14517; Accuracy is 0.33333\n","Epoch 4, Batch 180: Loss is 1.35284; Accuracy is 0.66667\n","Epoch 4, Batch 190: Loss is 0.95779; Accuracy is 0.66667\n","Epoch 4, Batch 200: Loss is 1.67596; Accuracy is 0.00000\n","Epoch 4, Batch 210: Loss is 1.77910; Accuracy is 0.66667\n","Epoch 4, Batch 220: Loss is 0.91316; Accuracy is 0.66667\n","Epoch 4, Batch 230: Loss is 0.63151; Accuracy is 1.00000\n","Epoch 4, Batch 240: Loss is 0.28812; Accuracy is 1.00000\n","Epoch 4, Batch 250: Loss is 0.61197; Accuracy is 0.66667\n","Epoch 4, Batch 260: Loss is 0.95422; Accuracy is 0.66667\n","Epoch 4, Batch 270: Loss is 0.87920; Accuracy is 0.66667\n","Epoch 4, Batch 280: Loss is 0.55595; Accuracy is 1.00000\n","Epoch 4, Batch 290: Loss is 2.87745; Accuracy is 0.33333\n","Epoch 4, Batch 300: Loss is 1.18074; Accuracy is 0.66667\n","Epoch 4, Batch 310: Loss is 1.12123; Accuracy is 0.33333\n","Epoch 4, Batch 320: Loss is 1.65458; Accuracy is 0.33333\n","Epoch 4, Batch 330: Loss is 0.45036; Accuracy is 1.00000\n","Epoch 4, Batch 340: Loss is 0.90126; Accuracy is 0.66667\n","Epoch 4, Batch 350: Loss is 1.04353; Accuracy is 0.66667\n","Epoch 4, Batch 360: Loss is 2.72598; Accuracy is 0.33333\n","Epoch 4, Batch 370: Loss is 0.78041; Accuracy is 1.00000\n","Epoch 4, Batch 380: Loss is 0.41685; Accuracy is 1.00000\n","Epoch 4: Average loss is: 1.35931; Average accuracy is: 0.53106\n","Test loss is 2.01259; Accuracy is 0.44063\n","Epoch 5, Batch 0: Loss is 1.33257; Accuracy is 0.33333\n","Epoch 5, Batch 10: Loss is 0.86888; Accuracy is 0.66667\n","Epoch 5, Batch 20: Loss is 0.39970; Accuracy is 1.00000\n","Epoch 5, Batch 30: Loss is 2.07064; Accuracy is 0.33333\n","Epoch 5, Batch 40: Loss is 0.90941; Accuracy is 0.66667\n","Epoch 5, Batch 50: Loss is 1.34940; Accuracy is 0.66667\n","Epoch 5, Batch 60: Loss is 0.67551; Accuracy is 1.00000\n","Epoch 5, Batch 70: Loss is 0.92470; Accuracy is 0.66667\n","Epoch 5, Batch 80: Loss is 2.26697; Accuracy is 0.00000\n","Epoch 5, Batch 90: Loss is 0.89209; Accuracy is 0.33333\n","Epoch 5, Batch 100: Loss is 0.19708; Accuracy is 1.00000\n","Epoch 5, Batch 110: Loss is 2.88307; Accuracy is 0.33333\n","Epoch 5, Batch 120: Loss is 1.39120; Accuracy is 0.33333\n","Epoch 5, Batch 130: Loss is 1.54625; Accuracy is 0.33333\n","Epoch 5, Batch 140: Loss is 1.77602; Accuracy is 0.66667\n","Epoch 5, Batch 150: Loss is 0.07931; Accuracy is 1.00000\n","Epoch 5, Batch 160: Loss is 0.37037; Accuracy is 1.00000\n","Epoch 5, Batch 170: Loss is 0.72554; Accuracy is 0.66667\n","Epoch 5, Batch 180: Loss is 0.55198; Accuracy is 1.00000\n","Epoch 5, Batch 190: Loss is 1.20850; Accuracy is 0.66667\n","Epoch 5, Batch 200: Loss is 0.71838; Accuracy is 0.66667\n","Epoch 5, Batch 210: Loss is 2.10773; Accuracy is 0.33333\n","Epoch 5, Batch 220: Loss is 1.79685; Accuracy is 0.33333\n","Epoch 5, Batch 230: Loss is 0.51960; Accuracy is 1.00000\n","Epoch 5, Batch 240: Loss is 1.57321; Accuracy is 0.66667\n","Epoch 5, Batch 250: Loss is 1.34430; Accuracy is 0.66667\n","Epoch 5, Batch 260: Loss is 0.55578; Accuracy is 0.66667\n","Epoch 5, Batch 270: Loss is 2.02688; Accuracy is 0.33333\n","Epoch 5, Batch 280: Loss is 1.52618; Accuracy is 0.66667\n","Epoch 5, Batch 290: Loss is 0.23508; Accuracy is 1.00000\n","Epoch 5, Batch 300: Loss is 0.42373; Accuracy is 1.00000\n","Epoch 5, Batch 310: Loss is 3.41875; Accuracy is 0.00000\n","Epoch 5, Batch 320: Loss is 1.17187; Accuracy is 0.66667\n","Epoch 5, Batch 330: Loss is 1.25701; Accuracy is 0.33333\n","Epoch 5, Batch 340: Loss is 1.18399; Accuracy is 0.66667\n","Epoch 5, Batch 350: Loss is 0.77007; Accuracy is 0.66667\n","Epoch 5, Batch 360: Loss is 0.80616; Accuracy is 0.66667\n","Epoch 5, Batch 370: Loss is 1.33939; Accuracy is 0.33333\n","Epoch 5, Batch 380: Loss is 0.52360; Accuracy is 1.00000\n","Epoch 5: Average loss is: 1.21135; Average accuracy is: 0.60017\n","Test loss is 1.93266; Accuracy is 0.48438\n","Epoch 6, Batch 0: Loss is 1.68772; Accuracy is 0.66667\n","Epoch 6, Batch 10: Loss is 0.45588; Accuracy is 0.66667\n","Epoch 6, Batch 20: Loss is 1.73899; Accuracy is 0.00000\n","Epoch 6, Batch 30: Loss is 1.48245; Accuracy is 0.00000\n","Epoch 6, Batch 40: Loss is 1.49092; Accuracy is 0.33333\n","Epoch 6, Batch 50: Loss is 0.29024; Accuracy is 1.00000\n","Epoch 6, Batch 60: Loss is 0.34167; Accuracy is 1.00000\n","Epoch 6, Batch 70: Loss is 1.60844; Accuracy is 0.33333\n","Epoch 6, Batch 80: Loss is 0.54810; Accuracy is 0.66667\n","Epoch 6, Batch 90: Loss is 0.08470; Accuracy is 1.00000\n","Epoch 6, Batch 100: Loss is 1.12173; Accuracy is 0.66667\n","Epoch 6, Batch 110: Loss is 0.44461; Accuracy is 0.66667\n","Epoch 6, Batch 120: Loss is 0.89085; Accuracy is 0.66667\n","Epoch 6, Batch 130: Loss is 0.10859; Accuracy is 1.00000\n","Epoch 6, Batch 140: Loss is 1.27716; Accuracy is 0.66667\n","Epoch 6, Batch 150: Loss is 0.69972; Accuracy is 0.66667\n","Epoch 6, Batch 160: Loss is 0.17226; Accuracy is 1.00000\n","Epoch 6, Batch 170: Loss is 0.76249; Accuracy is 0.66667\n","Epoch 6, Batch 180: Loss is 0.76576; Accuracy is 0.66667\n","Epoch 6, Batch 190: Loss is 1.84486; Accuracy is 0.33333\n","Epoch 6, Batch 200: Loss is 0.95847; Accuracy is 1.00000\n","Epoch 6, Batch 210: Loss is 1.14013; Accuracy is 0.33333\n","Epoch 6, Batch 220: Loss is 0.33387; Accuracy is 1.00000\n","Epoch 6, Batch 230: Loss is 1.83060; Accuracy is 0.66667\n","Epoch 6, Batch 240: Loss is 1.62620; Accuracy is 0.33333\n","Epoch 6, Batch 250: Loss is 1.18010; Accuracy is 0.66667\n","Epoch 6, Batch 260: Loss is 0.03361; Accuracy is 1.00000\n","Epoch 6, Batch 270: Loss is 1.11857; Accuracy is 0.33333\n","Epoch 6, Batch 280: Loss is 0.33294; Accuracy is 1.00000\n","Epoch 6, Batch 290: Loss is 2.69072; Accuracy is 0.33333\n","Epoch 6, Batch 300: Loss is 0.89777; Accuracy is 0.66667\n","Epoch 6, Batch 310: Loss is 0.62826; Accuracy is 1.00000\n","Epoch 6, Batch 320: Loss is 0.85611; Accuracy is 0.66667\n","Epoch 6, Batch 330: Loss is 1.12882; Accuracy is 0.33333\n","Epoch 6, Batch 340: Loss is 2.35357; Accuracy is 0.33333\n","Epoch 6, Batch 350: Loss is 0.27299; Accuracy is 1.00000\n","Epoch 6, Batch 360: Loss is 1.06383; Accuracy is 0.33333\n","Epoch 6, Batch 370: Loss is 1.55219; Accuracy is 0.66667\n","Epoch 6, Batch 380: Loss is 1.30047; Accuracy is 0.66667\n","Epoch 6: Average loss is: 0.97626; Average accuracy is: 0.67367\n","Test loss is 2.17435; Accuracy is 0.45312\n","Epoch 7, Batch 0: Loss is 0.05009; Accuracy is 1.00000\n","Epoch 7, Batch 10: Loss is 1.26916; Accuracy is 0.66667\n","Epoch 7, Batch 20: Loss is 1.01791; Accuracy is 0.33333\n","Epoch 7, Batch 30: Loss is 0.90126; Accuracy is 0.33333\n","Epoch 7, Batch 40: Loss is 0.38237; Accuracy is 1.00000\n","Epoch 7, Batch 50: Loss is 6.57577; Accuracy is 0.00000\n","Epoch 7, Batch 60: Loss is 0.63772; Accuracy is 0.66667\n","Epoch 7, Batch 70: Loss is 2.19015; Accuracy is 0.33333\n","Epoch 7, Batch 80: Loss is 0.42625; Accuracy is 1.00000\n","Epoch 7, Batch 90: Loss is 0.12355; Accuracy is 1.00000\n","Epoch 7, Batch 100: Loss is 1.72529; Accuracy is 0.66667\n","Epoch 7, Batch 110: Loss is 0.97101; Accuracy is 0.66667\n","Epoch 7, Batch 120: Loss is 0.40783; Accuracy is 1.00000\n","Epoch 7, Batch 130: Loss is 1.61137; Accuracy is 0.33333\n","Epoch 7, Batch 140: Loss is 0.90936; Accuracy is 0.66667\n","Epoch 7, Batch 150: Loss is 0.93955; Accuracy is 0.66667\n","Epoch 7, Batch 160: Loss is 0.24455; Accuracy is 1.00000\n","Epoch 7, Batch 170: Loss is 0.07217; Accuracy is 1.00000\n","Epoch 7, Batch 180: Loss is 0.85731; Accuracy is 0.66667\n","Epoch 7, Batch 190: Loss is 0.61434; Accuracy is 0.66667\n","Epoch 7, Batch 200: Loss is 0.77635; Accuracy is 0.66667\n","Epoch 7, Batch 210: Loss is 0.87974; Accuracy is 0.66667\n","Epoch 7, Batch 220: Loss is 0.25712; Accuracy is 1.00000\n","Epoch 7, Batch 230: Loss is 0.42977; Accuracy is 1.00000\n","Epoch 7, Batch 240: Loss is 0.83420; Accuracy is 0.66667\n","Epoch 7, Batch 250: Loss is 0.42519; Accuracy is 1.00000\n","Epoch 7, Batch 260: Loss is 1.30222; Accuracy is 0.66667\n","Epoch 7, Batch 270: Loss is 0.34409; Accuracy is 1.00000\n","Epoch 7, Batch 280: Loss is 1.03732; Accuracy is 0.33333\n","Epoch 7, Batch 290: Loss is 0.95601; Accuracy is 0.66667\n","Epoch 7, Batch 300: Loss is 1.42014; Accuracy is 0.33333\n","Epoch 7, Batch 310: Loss is 1.08969; Accuracy is 0.66667\n","Epoch 7, Batch 320: Loss is 0.51645; Accuracy is 0.66667\n","Epoch 7, Batch 330: Loss is 0.57114; Accuracy is 0.66667\n","Epoch 7, Batch 340: Loss is 0.41072; Accuracy is 1.00000\n","Epoch 7, Batch 350: Loss is 0.33147; Accuracy is 1.00000\n","Epoch 7, Batch 360: Loss is 0.65589; Accuracy is 0.66667\n","Epoch 7, Batch 370: Loss is 1.03860; Accuracy is 0.66667\n","Epoch 7, Batch 380: Loss is 0.47711; Accuracy is 0.66667\n","Epoch 7: Average loss is: 0.83520; Average accuracy is: 0.71391\n","Test loss is 3.96011; Accuracy is 0.35000\n","Epoch 8, Batch 0: Loss is 2.45193; Accuracy is 0.33333\n","Epoch 8, Batch 10: Loss is 0.24843; Accuracy is 1.00000\n","Epoch 8, Batch 20: Loss is 1.92643; Accuracy is 0.66667\n","Epoch 8, Batch 30: Loss is 0.16909; Accuracy is 1.00000\n","Epoch 8, Batch 40: Loss is 1.77852; Accuracy is 0.33333\n","Epoch 8, Batch 50: Loss is 0.02646; Accuracy is 1.00000\n","Epoch 8, Batch 60: Loss is 0.61462; Accuracy is 0.66667\n","Epoch 8, Batch 70: Loss is 2.89819; Accuracy is 0.33333\n","Epoch 8, Batch 80: Loss is 2.08717; Accuracy is 0.33333\n","Epoch 8, Batch 90: Loss is 0.63931; Accuracy is 0.66667\n","Epoch 8, Batch 100: Loss is 1.05052; Accuracy is 0.66667\n","Epoch 8, Batch 110: Loss is 0.09124; Accuracy is 1.00000\n","Epoch 8, Batch 120: Loss is 0.01202; Accuracy is 1.00000\n","Epoch 8, Batch 130: Loss is 2.27791; Accuracy is 0.00000\n","Epoch 8, Batch 140: Loss is 1.50829; Accuracy is 0.33333\n","Epoch 8, Batch 150: Loss is 2.25757; Accuracy is 0.66667\n","Epoch 8, Batch 160: Loss is 1.53204; Accuracy is 0.00000\n","Epoch 8, Batch 170: Loss is 0.33820; Accuracy is 1.00000\n","Epoch 8, Batch 180: Loss is 0.25262; Accuracy is 1.00000\n","Epoch 8, Batch 190: Loss is 0.82284; Accuracy is 0.66667\n","Epoch 8, Batch 200: Loss is 1.63400; Accuracy is 0.66667\n","Epoch 8, Batch 210: Loss is 0.02124; Accuracy is 1.00000\n","Epoch 8, Batch 220: Loss is 1.99646; Accuracy is 0.33333\n","Epoch 8, Batch 230: Loss is 0.43349; Accuracy is 1.00000\n","Epoch 8, Batch 240: Loss is 0.84659; Accuracy is 0.66667\n","Epoch 8, Batch 250: Loss is 0.13376; Accuracy is 1.00000\n","Epoch 8, Batch 260: Loss is 0.08140; Accuracy is 1.00000\n","Epoch 8, Batch 270: Loss is 0.53515; Accuracy is 1.00000\n","Epoch 8, Batch 280: Loss is 1.43343; Accuracy is 0.66667\n","Epoch 8, Batch 290: Loss is 0.42214; Accuracy is 0.66667\n","Epoch 8, Batch 300: Loss is 0.50577; Accuracy is 0.66667\n","Epoch 8, Batch 310: Loss is 1.46087; Accuracy is 0.66667\n","Epoch 8, Batch 320: Loss is 0.43123; Accuracy is 0.66667\n","Epoch 8, Batch 330: Loss is 1.60709; Accuracy is 0.33333\n","Epoch 8, Batch 340: Loss is 1.21042; Accuracy is 0.66667\n","Epoch 8, Batch 350: Loss is 0.53210; Accuracy is 0.66667\n","Epoch 8, Batch 360: Loss is 0.03730; Accuracy is 1.00000\n","Epoch 8, Batch 370: Loss is 2.11550; Accuracy is 0.66667\n","Epoch 8, Batch 380: Loss is 0.70850; Accuracy is 0.66667\n","Epoch 8: Average loss is: 0.87729; Average accuracy is: 0.70954\n","Test loss is 2.13274; Accuracy is 0.42500\n","Epoch 9, Batch 0: Loss is 0.12360; Accuracy is 1.00000\n","Epoch 9, Batch 10: Loss is 1.17060; Accuracy is 0.66667\n","Epoch 9, Batch 20: Loss is 0.98916; Accuracy is 0.33333\n","Epoch 9, Batch 30: Loss is 0.52576; Accuracy is 0.66667\n","Epoch 9, Batch 40: Loss is 1.33382; Accuracy is 0.66667\n","Epoch 9, Batch 50: Loss is 0.77475; Accuracy is 0.66667\n","Epoch 9, Batch 60: Loss is 0.12040; Accuracy is 1.00000\n","Epoch 9, Batch 70: Loss is 0.24757; Accuracy is 1.00000\n","Epoch 9, Batch 80: Loss is 0.66672; Accuracy is 0.66667\n","Epoch 9, Batch 90: Loss is 0.49883; Accuracy is 0.66667\n","Epoch 9, Batch 100: Loss is 0.01699; Accuracy is 1.00000\n","Epoch 9, Batch 110: Loss is 0.28312; Accuracy is 1.00000\n","Epoch 9, Batch 120: Loss is 1.75210; Accuracy is 0.66667\n","Epoch 9, Batch 130: Loss is 0.34390; Accuracy is 1.00000\n","Epoch 9, Batch 140: Loss is 1.69017; Accuracy is 0.33333\n","Epoch 9, Batch 150: Loss is 0.40161; Accuracy is 0.66667\n","Epoch 9, Batch 160: Loss is 0.79081; Accuracy is 0.33333\n","Epoch 9, Batch 170: Loss is 1.23533; Accuracy is 0.33333\n","Epoch 9, Batch 180: Loss is 1.15988; Accuracy is 0.33333\n","Epoch 9, Batch 190: Loss is 0.42905; Accuracy is 1.00000\n","Epoch 9, Batch 200: Loss is 0.42666; Accuracy is 0.66667\n","Epoch 9, Batch 210: Loss is 0.12010; Accuracy is 1.00000\n","Epoch 9, Batch 220: Loss is 0.22648; Accuracy is 1.00000\n","Epoch 9, Batch 230: Loss is 0.47634; Accuracy is 1.00000\n","Epoch 9, Batch 240: Loss is 0.14398; Accuracy is 1.00000\n","Epoch 9, Batch 250: Loss is 0.29942; Accuracy is 1.00000\n","Epoch 9, Batch 260: Loss is 0.24147; Accuracy is 1.00000\n","Epoch 9, Batch 270: Loss is 1.19972; Accuracy is 0.66667\n","Epoch 9, Batch 280: Loss is 0.35696; Accuracy is 1.00000\n","Epoch 9, Batch 290: Loss is 1.06640; Accuracy is 0.33333\n","Epoch 9, Batch 300: Loss is 0.89296; Accuracy is 0.66667\n","Epoch 9, Batch 310: Loss is 0.55981; Accuracy is 0.66667\n","Epoch 9, Batch 320: Loss is 1.03474; Accuracy is 0.66667\n","Epoch 9, Batch 330: Loss is 0.58130; Accuracy is 1.00000\n","Epoch 9, Batch 340: Loss is 0.50253; Accuracy is 1.00000\n","Epoch 9, Batch 350: Loss is 0.34497; Accuracy is 1.00000\n","Epoch 9, Batch 360: Loss is 0.00221; Accuracy is 1.00000\n","Epoch 9, Batch 370: Loss is 0.36693; Accuracy is 1.00000\n","Epoch 9, Batch 380: Loss is 0.09825; Accuracy is 1.00000\n","Epoch 9: Average loss is: 0.61731; Average accuracy is: 0.80227\n","Test loss is 2.31115; Accuracy is 0.50938\n","Epoch 10, Batch 0: Loss is 0.10515; Accuracy is 1.00000\n","Epoch 10, Batch 10: Loss is 0.07555; Accuracy is 1.00000\n","Epoch 10, Batch 20: Loss is 0.29900; Accuracy is 1.00000\n","Epoch 10, Batch 30: Loss is 0.65220; Accuracy is 0.66667\n","Epoch 10, Batch 40: Loss is 0.34925; Accuracy is 1.00000\n","Epoch 10, Batch 50: Loss is 0.57605; Accuracy is 0.66667\n","Epoch 10, Batch 60: Loss is 1.08726; Accuracy is 0.66667\n","Epoch 10, Batch 70: Loss is 1.16186; Accuracy is 0.66667\n","Epoch 10, Batch 80: Loss is 0.30983; Accuracy is 1.00000\n","Epoch 10, Batch 90: Loss is 0.23318; Accuracy is 1.00000\n","Epoch 10, Batch 100: Loss is 0.00527; Accuracy is 1.00000\n","Epoch 10, Batch 110: Loss is 0.35154; Accuracy is 0.66667\n","Epoch 10, Batch 120: Loss is 0.11820; Accuracy is 1.00000\n","Epoch 10, Batch 130: Loss is 0.67171; Accuracy is 0.66667\n","Epoch 10, Batch 140: Loss is 2.29229; Accuracy is 0.33333\n","Epoch 10, Batch 150: Loss is 0.30319; Accuracy is 1.00000\n","Epoch 10, Batch 160: Loss is 1.40352; Accuracy is 0.66667\n","Epoch 10, Batch 170: Loss is 0.29929; Accuracy is 1.00000\n","Epoch 10, Batch 180: Loss is 0.70739; Accuracy is 1.00000\n","Epoch 10, Batch 190: Loss is 1.14773; Accuracy is 0.33333\n","Epoch 10, Batch 200: Loss is 0.55970; Accuracy is 0.66667\n","Epoch 10, Batch 210: Loss is 0.07065; Accuracy is 1.00000\n","Epoch 10, Batch 220: Loss is 0.09907; Accuracy is 1.00000\n","Epoch 10, Batch 230: Loss is 0.65307; Accuracy is 1.00000\n","Epoch 10, Batch 240: Loss is 0.22784; Accuracy is 1.00000\n","Epoch 10, Batch 250: Loss is 1.09482; Accuracy is 0.66667\n","Epoch 10, Batch 260: Loss is 0.76129; Accuracy is 0.66667\n","Epoch 10, Batch 270: Loss is 1.86318; Accuracy is 0.33333\n","Epoch 10, Batch 280: Loss is 1.30823; Accuracy is 0.66667\n","Epoch 10, Batch 290: Loss is 0.67045; Accuracy is 0.66667\n","Epoch 10, Batch 300: Loss is 0.39167; Accuracy is 1.00000\n","Epoch 10, Batch 310: Loss is 1.51961; Accuracy is 0.33333\n","Epoch 10, Batch 320: Loss is 1.27625; Accuracy is 0.66667\n","Epoch 10, Batch 330: Loss is 0.07712; Accuracy is 1.00000\n","Epoch 10, Batch 340: Loss is 0.36510; Accuracy is 1.00000\n","Epoch 10, Batch 350: Loss is 0.67620; Accuracy is 0.66667\n","Epoch 10, Batch 360: Loss is 0.02047; Accuracy is 1.00000\n","Epoch 10, Batch 370: Loss is 1.48031; Accuracy is 0.66667\n","Epoch 10, Batch 380: Loss is 0.62234; Accuracy is 0.66667\n","Epoch 10: Average loss is: 0.66039; Average accuracy is: 0.79353\n","Test loss is 2.34347; Accuracy is 0.48438\n","Epoch 11, Batch 0: Loss is 0.19323; Accuracy is 1.00000\n","Epoch 11, Batch 10: Loss is 0.05307; Accuracy is 1.00000\n","Epoch 11, Batch 20: Loss is 0.03858; Accuracy is 1.00000\n","Epoch 11, Batch 30: Loss is 0.01446; Accuracy is 1.00000\n","Epoch 11, Batch 40: Loss is 0.18103; Accuracy is 1.00000\n","Epoch 11, Batch 50: Loss is 0.43773; Accuracy is 1.00000\n","Epoch 11, Batch 60: Loss is 0.27239; Accuracy is 1.00000\n","Epoch 11, Batch 70: Loss is 1.27490; Accuracy is 0.33333\n","Epoch 11, Batch 80: Loss is 0.18743; Accuracy is 1.00000\n","Epoch 11, Batch 90: Loss is 1.25373; Accuracy is 0.66667\n","Epoch 11, Batch 100: Loss is 0.29599; Accuracy is 1.00000\n","Epoch 11, Batch 110: Loss is 4.08491; Accuracy is 0.00000\n","Epoch 11, Batch 120: Loss is 0.24318; Accuracy is 1.00000\n","Epoch 11, Batch 130: Loss is 0.00664; Accuracy is 1.00000\n","Epoch 11, Batch 140: Loss is 0.48406; Accuracy is 1.00000\n","Epoch 11, Batch 150: Loss is 0.37594; Accuracy is 0.66667\n","Epoch 11, Batch 160: Loss is 0.73664; Accuracy is 0.66667\n","Epoch 11, Batch 170: Loss is 0.39107; Accuracy is 1.00000\n","Epoch 11, Batch 180: Loss is 0.32561; Accuracy is 1.00000\n","Epoch 11, Batch 190: Loss is 0.03570; Accuracy is 1.00000\n","Epoch 11, Batch 200: Loss is 1.31722; Accuracy is 0.33333\n","Epoch 11, Batch 210: Loss is 0.17264; Accuracy is 1.00000\n","Epoch 11, Batch 220: Loss is 0.00486; Accuracy is 1.00000\n","Epoch 11, Batch 230: Loss is 0.18053; Accuracy is 1.00000\n","Epoch 11, Batch 240: Loss is 0.00009; Accuracy is 1.00000\n","Epoch 11, Batch 250: Loss is 0.28326; Accuracy is 0.66667\n","Epoch 11, Batch 260: Loss is 0.00310; Accuracy is 1.00000\n","Epoch 11, Batch 270: Loss is 0.00110; Accuracy is 1.00000\n","Epoch 11, Batch 280: Loss is 0.09267; Accuracy is 1.00000\n","Epoch 11, Batch 290: Loss is 0.01147; Accuracy is 1.00000\n","Epoch 11, Batch 300: Loss is 2.35242; Accuracy is 0.66667\n","Epoch 11, Batch 310: Loss is 3.98073; Accuracy is 0.66667\n","Epoch 11, Batch 320: Loss is 0.91923; Accuracy is 0.33333\n","Epoch 11, Batch 330: Loss is 0.44207; Accuracy is 1.00000\n","Epoch 11, Batch 340: Loss is 0.39048; Accuracy is 1.00000\n","Epoch 11, Batch 350: Loss is 1.50013; Accuracy is 0.00000\n","Epoch 11, Batch 360: Loss is 0.43403; Accuracy is 0.66667\n","Epoch 11, Batch 370: Loss is 1.32821; Accuracy is 0.33333\n","Epoch 11, Batch 380: Loss is 1.22978; Accuracy is 0.33333\n","Epoch 11: Average loss is: 0.64650; Average accuracy is: 0.79878\n","Test loss is 2.02079; Accuracy is 0.50313\n","Epoch 12, Batch 0: Loss is 0.00115; Accuracy is 1.00000\n","Epoch 12, Batch 10: Loss is 0.00377; Accuracy is 1.00000\n","Epoch 12, Batch 20: Loss is 0.09773; Accuracy is 1.00000\n","Epoch 12, Batch 30: Loss is 0.34688; Accuracy is 0.66667\n","Epoch 12, Batch 40: Loss is 0.00272; Accuracy is 1.00000\n","Epoch 12, Batch 50: Loss is 0.22749; Accuracy is 1.00000\n","Epoch 12, Batch 60: Loss is 1.76981; Accuracy is 0.33333\n","Epoch 12, Batch 70: Loss is 0.00046; Accuracy is 1.00000\n","Epoch 12, Batch 80: Loss is 0.85320; Accuracy is 0.33333\n","Epoch 12, Batch 90: Loss is 0.22896; Accuracy is 1.00000\n","Epoch 12, Batch 100: Loss is 0.58404; Accuracy is 0.66667\n","Epoch 12, Batch 110: Loss is 1.09044; Accuracy is 0.66667\n","Epoch 12, Batch 120: Loss is 0.08303; Accuracy is 1.00000\n","Epoch 12, Batch 130: Loss is 0.32571; Accuracy is 1.00000\n","Epoch 12, Batch 140: Loss is 0.01068; Accuracy is 1.00000\n","Epoch 12, Batch 150: Loss is 0.64410; Accuracy is 0.66667\n","Epoch 12, Batch 160: Loss is 0.98733; Accuracy is 0.66667\n","Epoch 12, Batch 170: Loss is 0.86137; Accuracy is 0.66667\n","Epoch 12, Batch 180: Loss is 0.87293; Accuracy is 0.66667\n","Epoch 12, Batch 190: Loss is 1.67870; Accuracy is 0.66667\n","Epoch 12, Batch 200: Loss is 0.27792; Accuracy is 1.00000\n","Epoch 12, Batch 210: Loss is 4.58596; Accuracy is 0.33333\n","Epoch 12, Batch 220: Loss is 1.76549; Accuracy is 0.66667\n","Epoch 12, Batch 230: Loss is 0.36130; Accuracy is 1.00000\n","Epoch 12, Batch 240: Loss is 0.54820; Accuracy is 0.66667\n","Epoch 12, Batch 250: Loss is 0.47397; Accuracy is 0.66667\n","Epoch 12, Batch 260: Loss is 0.13532; Accuracy is 1.00000\n","Epoch 12, Batch 270: Loss is 0.59537; Accuracy is 0.66667\n","Epoch 12, Batch 280: Loss is 0.16651; Accuracy is 1.00000\n","Epoch 12, Batch 290: Loss is 0.10281; Accuracy is 1.00000\n","Epoch 12, Batch 300: Loss is 0.54982; Accuracy is 0.66667\n","Epoch 12, Batch 310: Loss is 0.86849; Accuracy is 0.66667\n","Epoch 12, Batch 320: Loss is 5.68956; Accuracy is 0.00000\n","Epoch 12, Batch 330: Loss is 0.45921; Accuracy is 0.66667\n","Epoch 12, Batch 340: Loss is 1.00847; Accuracy is 0.66667\n","Epoch 12, Batch 350: Loss is 0.09745; Accuracy is 1.00000\n","Epoch 12, Batch 360: Loss is 0.38647; Accuracy is 0.66667\n","Epoch 12, Batch 370: Loss is 0.04299; Accuracy is 1.00000\n","Epoch 12, Batch 380: Loss is 0.04556; Accuracy is 1.00000\n","Epoch 12: Average loss is: 0.53792; Average accuracy is: 0.83640\n","Test loss is 2.81825; Accuracy is 0.49062\n","Epoch 13, Batch 0: Loss is 0.00091; Accuracy is 1.00000\n","Epoch 13, Batch 10: Loss is 0.00629; Accuracy is 1.00000\n","Epoch 13, Batch 20: Loss is 0.68436; Accuracy is 0.66667\n","Epoch 13, Batch 30: Loss is 0.97698; Accuracy is 0.66667\n","Epoch 13, Batch 40: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 13, Batch 50: Loss is 0.70084; Accuracy is 0.66667\n","Epoch 13, Batch 60: Loss is 0.97173; Accuracy is 0.66667\n","Epoch 13, Batch 70: Loss is 0.09127; Accuracy is 1.00000\n","Epoch 13, Batch 80: Loss is 0.24066; Accuracy is 1.00000\n","Epoch 13, Batch 90: Loss is 0.00575; Accuracy is 1.00000\n","Epoch 13, Batch 100: Loss is 1.46207; Accuracy is 0.33333\n","Epoch 13, Batch 110: Loss is 0.07896; Accuracy is 1.00000\n","Epoch 13, Batch 120: Loss is 1.02431; Accuracy is 0.66667\n","Epoch 13, Batch 130: Loss is 2.54985; Accuracy is 0.33333\n","Epoch 13, Batch 140: Loss is 1.44261; Accuracy is 0.66667\n","Epoch 13, Batch 150: Loss is 0.07455; Accuracy is 1.00000\n","Epoch 13, Batch 160: Loss is 0.12868; Accuracy is 1.00000\n","Epoch 13, Batch 170: Loss is 0.03430; Accuracy is 1.00000\n","Epoch 13, Batch 180: Loss is 0.01996; Accuracy is 1.00000\n","Epoch 13, Batch 190: Loss is 0.15523; Accuracy is 1.00000\n","Epoch 13, Batch 200: Loss is 0.94019; Accuracy is 0.66667\n","Epoch 13, Batch 210: Loss is 0.01551; Accuracy is 1.00000\n","Epoch 13, Batch 220: Loss is 0.30547; Accuracy is 1.00000\n","Epoch 13, Batch 230: Loss is 0.77143; Accuracy is 0.66667\n","Epoch 13, Batch 240: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 13, Batch 250: Loss is 0.00284; Accuracy is 1.00000\n","Epoch 13, Batch 260: Loss is 0.60269; Accuracy is 0.66667\n","Epoch 13, Batch 270: Loss is 1.80268; Accuracy is 0.66667\n","Epoch 13, Batch 280: Loss is 0.02847; Accuracy is 1.00000\n","Epoch 13, Batch 290: Loss is 0.12624; Accuracy is 1.00000\n","Epoch 13, Batch 300: Loss is 0.02639; Accuracy is 1.00000\n","Epoch 13, Batch 310: Loss is 0.00254; Accuracy is 1.00000\n","Epoch 13, Batch 320: Loss is 0.80935; Accuracy is 0.66667\n","Epoch 13, Batch 330: Loss is 1.63494; Accuracy is 0.66667\n","Epoch 13, Batch 340: Loss is 2.24372; Accuracy is 0.33333\n","Epoch 13, Batch 350: Loss is 0.00043; Accuracy is 1.00000\n","Epoch 13, Batch 360: Loss is 0.06691; Accuracy is 1.00000\n","Epoch 13, Batch 370: Loss is 0.48439; Accuracy is 0.66667\n","Epoch 13, Batch 380: Loss is 0.04731; Accuracy is 1.00000\n","Epoch 13: Average loss is: 0.39303; Average accuracy is: 0.87402\n","Test loss is 3.05896; Accuracy is 0.44688\n","Epoch 14, Batch 0: Loss is 0.11590; Accuracy is 1.00000\n","Epoch 14, Batch 10: Loss is 0.01396; Accuracy is 1.00000\n","Epoch 14, Batch 20: Loss is 0.07226; Accuracy is 1.00000\n","Epoch 14, Batch 30: Loss is 0.35072; Accuracy is 0.66667\n","Epoch 14, Batch 40: Loss is 0.01037; Accuracy is 1.00000\n","Epoch 14, Batch 50: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 14, Batch 60: Loss is 0.07852; Accuracy is 1.00000\n","Epoch 14, Batch 70: Loss is 1.77645; Accuracy is 0.33333\n","Epoch 14, Batch 80: Loss is 0.25911; Accuracy is 1.00000\n","Epoch 14, Batch 90: Loss is 0.03429; Accuracy is 1.00000\n","Epoch 14, Batch 100: Loss is 0.13790; Accuracy is 1.00000\n","Epoch 14, Batch 110: Loss is 0.81827; Accuracy is 0.66667\n","Epoch 14, Batch 120: Loss is 0.00050; Accuracy is 1.00000\n","Epoch 14, Batch 130: Loss is 0.08669; Accuracy is 1.00000\n","Epoch 14, Batch 140: Loss is 0.87583; Accuracy is 0.66667\n","Epoch 14, Batch 150: Loss is 0.01936; Accuracy is 1.00000\n","Epoch 14, Batch 160: Loss is 0.09639; Accuracy is 1.00000\n","Epoch 14, Batch 170: Loss is 0.11016; Accuracy is 1.00000\n","Epoch 14, Batch 180: Loss is 0.46094; Accuracy is 0.66667\n","Epoch 14, Batch 190: Loss is 0.05395; Accuracy is 1.00000\n","Epoch 14, Batch 200: Loss is 0.00081; Accuracy is 1.00000\n","Epoch 14, Batch 210: Loss is 0.04672; Accuracy is 1.00000\n","Epoch 14, Batch 220: Loss is 0.01724; Accuracy is 1.00000\n","Epoch 14, Batch 230: Loss is 0.15586; Accuracy is 1.00000\n","Epoch 14, Batch 240: Loss is 0.01479; Accuracy is 1.00000\n","Epoch 14, Batch 250: Loss is 0.12477; Accuracy is 1.00000\n","Epoch 14, Batch 260: Loss is 1.32786; Accuracy is 0.66667\n","Epoch 14, Batch 270: Loss is 0.00074; Accuracy is 1.00000\n","Epoch 14, Batch 280: Loss is 0.04672; Accuracy is 1.00000\n","Epoch 14, Batch 290: Loss is 0.05071; Accuracy is 1.00000\n","Epoch 14, Batch 300: Loss is 0.17580; Accuracy is 1.00000\n","Epoch 14, Batch 310: Loss is 1.41310; Accuracy is 0.33333\n","Epoch 14, Batch 320: Loss is 0.35977; Accuracy is 1.00000\n","Epoch 14, Batch 330: Loss is 0.57013; Accuracy is 1.00000\n","Epoch 14, Batch 340: Loss is 0.18481; Accuracy is 1.00000\n","Epoch 14, Batch 350: Loss is 0.00314; Accuracy is 1.00000\n","Epoch 14, Batch 360: Loss is 0.84545; Accuracy is 0.66667\n","Epoch 14, Batch 370: Loss is 0.28574; Accuracy is 1.00000\n","Epoch 14, Batch 380: Loss is 0.02528; Accuracy is 1.00000\n","Epoch 14: Average loss is: 0.37423; Average accuracy is: 0.88364\n","Test loss is 2.29581; Accuracy is 0.52812\n","Epoch 15, Batch 0: Loss is 0.18175; Accuracy is 1.00000\n","Epoch 15, Batch 10: Loss is 0.38355; Accuracy is 1.00000\n","Epoch 15, Batch 20: Loss is 0.32002; Accuracy is 0.66667\n","Epoch 15, Batch 30: Loss is 1.29217; Accuracy is 0.33333\n","Epoch 15, Batch 40: Loss is 0.32514; Accuracy is 1.00000\n","Epoch 15, Batch 50: Loss is 0.05965; Accuracy is 1.00000\n","Epoch 15, Batch 60: Loss is 0.00393; Accuracy is 1.00000\n","Epoch 15, Batch 70: Loss is 0.01006; Accuracy is 1.00000\n","Epoch 15, Batch 80: Loss is 1.29403; Accuracy is 0.66667\n","Epoch 15, Batch 90: Loss is 0.03529; Accuracy is 1.00000\n","Epoch 15, Batch 100: Loss is 0.21888; Accuracy is 1.00000\n","Epoch 15, Batch 110: Loss is 0.36055; Accuracy is 1.00000\n","Epoch 15, Batch 120: Loss is 0.27412; Accuracy is 1.00000\n","Epoch 15, Batch 130: Loss is 0.98468; Accuracy is 0.66667\n","Epoch 15, Batch 140: Loss is 0.52625; Accuracy is 0.66667\n","Epoch 15, Batch 150: Loss is 0.04248; Accuracy is 1.00000\n","Epoch 15, Batch 160: Loss is 0.00185; Accuracy is 1.00000\n","Epoch 15, Batch 170: Loss is 0.57977; Accuracy is 0.66667\n","Epoch 15, Batch 180: Loss is 0.19553; Accuracy is 1.00000\n","Epoch 15, Batch 190: Loss is 0.04219; Accuracy is 1.00000\n","Epoch 15, Batch 200: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 15, Batch 210: Loss is 0.06673; Accuracy is 1.00000\n","Epoch 15, Batch 220: Loss is 0.25615; Accuracy is 1.00000\n","Epoch 15, Batch 230: Loss is 0.81231; Accuracy is 0.66667\n","Epoch 15, Batch 240: Loss is 0.93006; Accuracy is 0.66667\n","Epoch 15, Batch 250: Loss is 0.84485; Accuracy is 0.66667\n","Epoch 15, Batch 260: Loss is 0.00088; Accuracy is 1.00000\n","Epoch 15, Batch 270: Loss is 0.06702; Accuracy is 1.00000\n","Epoch 15, Batch 280: Loss is 1.69651; Accuracy is 0.66667\n","Epoch 15, Batch 290: Loss is 0.15216; Accuracy is 1.00000\n","Epoch 15, Batch 300: Loss is 0.97682; Accuracy is 0.66667\n","Epoch 15, Batch 310: Loss is 0.40479; Accuracy is 1.00000\n","Epoch 15, Batch 320: Loss is 0.79364; Accuracy is 0.66667\n","Epoch 15, Batch 330: Loss is 0.94246; Accuracy is 0.66667\n","Epoch 15, Batch 340: Loss is 0.49324; Accuracy is 0.66667\n","Epoch 15, Batch 350: Loss is 0.28113; Accuracy is 1.00000\n","Epoch 15, Batch 360: Loss is 0.42323; Accuracy is 0.66667\n","Epoch 15, Batch 370: Loss is 0.12929; Accuracy is 1.00000\n","Epoch 15, Batch 380: Loss is 0.83218; Accuracy is 0.66667\n","Epoch 15: Average loss is: 0.48087; Average accuracy is: 0.86702\n","Test loss is 3.10273; Accuracy is 0.48438\n","Epoch 16, Batch 0: Loss is 0.08374; Accuracy is 1.00000\n","Epoch 16, Batch 10: Loss is 0.75181; Accuracy is 0.66667\n","Epoch 16, Batch 20: Loss is 0.11208; Accuracy is 1.00000\n","Epoch 16, Batch 30: Loss is 2.33825; Accuracy is 0.66667\n","Epoch 16, Batch 40: Loss is 0.21671; Accuracy is 1.00000\n","Epoch 16, Batch 50: Loss is 1.22806; Accuracy is 0.66667\n","Epoch 16, Batch 60: Loss is 0.20689; Accuracy is 1.00000\n","Epoch 16, Batch 70: Loss is 0.01744; Accuracy is 1.00000\n","Epoch 16, Batch 80: Loss is 1.26412; Accuracy is 0.33333\n","Epoch 16, Batch 90: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 16, Batch 100: Loss is 0.69061; Accuracy is 0.33333\n","Epoch 16, Batch 110: Loss is 0.00398; Accuracy is 1.00000\n","Epoch 16, Batch 120: Loss is 2.65950; Accuracy is 0.66667\n","Epoch 16, Batch 130: Loss is 0.08900; Accuracy is 1.00000\n","Epoch 16, Batch 140: Loss is 0.05076; Accuracy is 1.00000\n","Epoch 16, Batch 150: Loss is 0.02986; Accuracy is 1.00000\n","Epoch 16, Batch 160: Loss is 0.06135; Accuracy is 1.00000\n","Epoch 16, Batch 170: Loss is 0.07741; Accuracy is 1.00000\n","Epoch 16, Batch 180: Loss is 0.00940; Accuracy is 1.00000\n","Epoch 16, Batch 190: Loss is 0.09436; Accuracy is 1.00000\n","Epoch 16, Batch 200: Loss is 0.19938; Accuracy is 1.00000\n","Epoch 16, Batch 210: Loss is 0.19889; Accuracy is 1.00000\n","Epoch 16, Batch 220: Loss is 0.00008; Accuracy is 1.00000\n","Epoch 16, Batch 230: Loss is 0.00478; Accuracy is 1.00000\n","Epoch 16, Batch 240: Loss is 0.00220; Accuracy is 1.00000\n","Epoch 16, Batch 250: Loss is 1.15087; Accuracy is 0.33333\n","Epoch 16, Batch 260: Loss is 0.01889; Accuracy is 1.00000\n","Epoch 16, Batch 270: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 16, Batch 280: Loss is 1.10168; Accuracy is 0.66667\n","Epoch 16, Batch 290: Loss is 0.01145; Accuracy is 1.00000\n","Epoch 16, Batch 300: Loss is 0.54482; Accuracy is 0.66667\n","Epoch 16, Batch 310: Loss is 0.01647; Accuracy is 1.00000\n","Epoch 16, Batch 320: Loss is 0.19017; Accuracy is 1.00000\n","Epoch 16, Batch 330: Loss is 0.21403; Accuracy is 1.00000\n","Epoch 16, Batch 340: Loss is 0.02762; Accuracy is 1.00000\n","Epoch 16, Batch 350: Loss is 0.06698; Accuracy is 1.00000\n","Epoch 16, Batch 360: Loss is 0.28866; Accuracy is 1.00000\n","Epoch 16, Batch 370: Loss is 0.03782; Accuracy is 1.00000\n","Epoch 16, Batch 380: Loss is 0.20132; Accuracy is 1.00000\n","Epoch 16: Average loss is: 0.37200; Average accuracy is: 0.88889\n","Test loss is 2.50687; Accuracy is 0.53750\n","Epoch 17, Batch 0: Loss is 0.05983; Accuracy is 1.00000\n","Epoch 17, Batch 10: Loss is 1.47795; Accuracy is 0.33333\n","Epoch 17, Batch 20: Loss is 0.05351; Accuracy is 1.00000\n","Epoch 17, Batch 30: Loss is 0.41358; Accuracy is 0.66667\n","Epoch 17, Batch 40: Loss is 0.03165; Accuracy is 1.00000\n","Epoch 17, Batch 50: Loss is 0.35142; Accuracy is 0.66667\n","Epoch 17, Batch 60: Loss is 0.00163; Accuracy is 1.00000\n","Epoch 17, Batch 70: Loss is 0.30400; Accuracy is 0.66667\n","Epoch 17, Batch 80: Loss is 1.39427; Accuracy is 0.66667\n","Epoch 17, Batch 90: Loss is 0.00443; Accuracy is 1.00000\n","Epoch 17, Batch 100: Loss is 0.31972; Accuracy is 1.00000\n","Epoch 17, Batch 110: Loss is 0.23288; Accuracy is 1.00000\n","Epoch 17, Batch 120: Loss is 2.96132; Accuracy is 0.66667\n","Epoch 17, Batch 130: Loss is 0.67666; Accuracy is 0.66667\n","Epoch 17, Batch 140: Loss is 0.42492; Accuracy is 0.66667\n","Epoch 17, Batch 150: Loss is 0.95572; Accuracy is 0.66667\n","Epoch 17, Batch 160: Loss is 0.09404; Accuracy is 1.00000\n","Epoch 17, Batch 170: Loss is 0.13772; Accuracy is 1.00000\n","Epoch 17, Batch 180: Loss is 0.02947; Accuracy is 1.00000\n","Epoch 17, Batch 190: Loss is 0.30492; Accuracy is 1.00000\n","Epoch 17, Batch 200: Loss is 0.00569; Accuracy is 1.00000\n","Epoch 17, Batch 210: Loss is 0.32432; Accuracy is 0.66667\n","Epoch 17, Batch 220: Loss is 0.08438; Accuracy is 1.00000\n","Epoch 17, Batch 230: Loss is 1.39176; Accuracy is 0.33333\n","Epoch 17, Batch 240: Loss is 0.40561; Accuracy is 1.00000\n","Epoch 17, Batch 250: Loss is 0.05386; Accuracy is 1.00000\n","Epoch 17, Batch 260: Loss is 0.16833; Accuracy is 1.00000\n","Epoch 17, Batch 270: Loss is 0.00015; Accuracy is 1.00000\n","Epoch 17, Batch 280: Loss is 0.00288; Accuracy is 1.00000\n","Epoch 17, Batch 290: Loss is 0.00099; Accuracy is 1.00000\n","Epoch 17, Batch 300: Loss is 0.00056; Accuracy is 1.00000\n","Epoch 17, Batch 310: Loss is 0.00877; Accuracy is 1.00000\n","Epoch 17, Batch 320: Loss is 0.00525; Accuracy is 1.00000\n","Epoch 17, Batch 330: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 17, Batch 340: Loss is 0.05654; Accuracy is 1.00000\n","Epoch 17, Batch 350: Loss is 2.40309; Accuracy is 0.66667\n","Epoch 17, Batch 360: Loss is 1.95142; Accuracy is 0.66667\n","Epoch 17, Batch 370: Loss is 0.44546; Accuracy is 0.66667\n","Epoch 17, Batch 380: Loss is 0.14104; Accuracy is 1.00000\n","Epoch 17: Average loss is: 0.25157; Average accuracy is: 0.92388\n","Test loss is 1.97421; Accuracy is 0.51250\n","Epoch 18, Batch 0: Loss is 0.27071; Accuracy is 1.00000\n","Epoch 18, Batch 10: Loss is 0.00113; Accuracy is 1.00000\n","Epoch 18, Batch 20: Loss is 0.30626; Accuracy is 0.66667\n","Epoch 18, Batch 30: Loss is 0.06173; Accuracy is 1.00000\n","Epoch 18, Batch 40: Loss is 0.00551; Accuracy is 1.00000\n","Epoch 18, Batch 50: Loss is 0.01629; Accuracy is 1.00000\n","Epoch 18, Batch 60: Loss is 0.35589; Accuracy is 0.66667\n","Epoch 18, Batch 70: Loss is 0.09360; Accuracy is 1.00000\n","Epoch 18, Batch 80: Loss is 0.56746; Accuracy is 0.66667\n","Epoch 18, Batch 90: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 18, Batch 100: Loss is 0.94676; Accuracy is 0.66667\n","Epoch 18, Batch 110: Loss is 0.01817; Accuracy is 1.00000\n","Epoch 18, Batch 120: Loss is 0.04578; Accuracy is 1.00000\n","Epoch 18, Batch 130: Loss is 0.02008; Accuracy is 1.00000\n","Epoch 18, Batch 140: Loss is 0.01677; Accuracy is 1.00000\n","Epoch 18, Batch 150: Loss is 0.07637; Accuracy is 1.00000\n","Epoch 18, Batch 160: Loss is 0.00078; Accuracy is 1.00000\n","Epoch 18, Batch 170: Loss is 0.04222; Accuracy is 1.00000\n","Epoch 18, Batch 180: Loss is 0.75401; Accuracy is 0.66667\n","Epoch 18, Batch 190: Loss is 0.29349; Accuracy is 0.66667\n","Epoch 18, Batch 200: Loss is 0.01000; Accuracy is 1.00000\n","Epoch 18, Batch 210: Loss is 1.01449; Accuracy is 0.66667\n","Epoch 18, Batch 220: Loss is 0.19697; Accuracy is 1.00000\n","Epoch 18, Batch 230: Loss is 0.21267; Accuracy is 1.00000\n","Epoch 18, Batch 240: Loss is 0.01627; Accuracy is 1.00000\n","Epoch 18, Batch 250: Loss is 0.14014; Accuracy is 1.00000\n","Epoch 18, Batch 260: Loss is 0.93323; Accuracy is 0.66667\n","Epoch 18, Batch 270: Loss is 0.28074; Accuracy is 1.00000\n","Epoch 18, Batch 280: Loss is 0.21886; Accuracy is 1.00000\n","Epoch 18, Batch 290: Loss is 0.40523; Accuracy is 0.66667\n","Epoch 18, Batch 300: Loss is 0.54274; Accuracy is 0.66667\n","Epoch 18, Batch 310: Loss is 0.22674; Accuracy is 1.00000\n","Epoch 18, Batch 320: Loss is 0.00010; Accuracy is 1.00000\n","Epoch 18, Batch 330: Loss is 0.00187; Accuracy is 1.00000\n","Epoch 18, Batch 340: Loss is 1.67562; Accuracy is 0.66667\n","Epoch 18, Batch 350: Loss is 0.14165; Accuracy is 1.00000\n","Epoch 18, Batch 360: Loss is 2.61709; Accuracy is 0.66667\n","Epoch 18, Batch 370: Loss is 0.01413; Accuracy is 1.00000\n","Epoch 18, Batch 380: Loss is 0.10263; Accuracy is 1.00000\n","Epoch 18: Average loss is: 0.36197; Average accuracy is: 0.88189\n","Test loss is 4.14316; Accuracy is 0.40000\n","Epoch 19, Batch 0: Loss is 0.01223; Accuracy is 1.00000\n","Epoch 19, Batch 10: Loss is 0.00227; Accuracy is 1.00000\n","Epoch 19, Batch 20: Loss is 2.46996; Accuracy is 0.00000\n","Epoch 19, Batch 30: Loss is 0.49976; Accuracy is 1.00000\n","Epoch 19, Batch 40: Loss is 0.18627; Accuracy is 1.00000\n","Epoch 19, Batch 50: Loss is 0.01481; Accuracy is 1.00000\n","Epoch 19, Batch 60: Loss is 0.24898; Accuracy is 1.00000\n","Epoch 19, Batch 70: Loss is 0.03532; Accuracy is 1.00000\n","Epoch 19, Batch 80: Loss is 0.08327; Accuracy is 1.00000\n","Epoch 19, Batch 90: Loss is 0.07064; Accuracy is 1.00000\n","Epoch 19, Batch 100: Loss is 0.00147; Accuracy is 1.00000\n","Epoch 19, Batch 110: Loss is 0.00437; Accuracy is 1.00000\n","Epoch 19, Batch 120: Loss is 2.81575; Accuracy is 0.33333\n","Epoch 19, Batch 130: Loss is 2.05270; Accuracy is 0.33333\n","Epoch 19, Batch 140: Loss is 1.32338; Accuracy is 0.33333\n","Epoch 19, Batch 150: Loss is 1.65821; Accuracy is 0.33333\n","Epoch 19, Batch 160: Loss is 0.00067; Accuracy is 1.00000\n","Epoch 19, Batch 170: Loss is 0.51161; Accuracy is 0.66667\n","Epoch 19, Batch 180: Loss is 0.40027; Accuracy is 1.00000\n","Epoch 19, Batch 190: Loss is 0.19094; Accuracy is 1.00000\n","Epoch 19, Batch 200: Loss is 0.29062; Accuracy is 0.66667\n","Epoch 19, Batch 210: Loss is 0.10147; Accuracy is 1.00000\n","Epoch 19, Batch 220: Loss is 0.06770; Accuracy is 1.00000\n","Epoch 19, Batch 230: Loss is 0.00123; Accuracy is 1.00000\n","Epoch 19, Batch 240: Loss is 0.16692; Accuracy is 1.00000\n","Epoch 19, Batch 250: Loss is 0.00159; Accuracy is 1.00000\n","Epoch 19, Batch 260: Loss is 0.45940; Accuracy is 0.66667\n","Epoch 19, Batch 270: Loss is 0.00104; Accuracy is 1.00000\n","Epoch 19, Batch 280: Loss is 0.23711; Accuracy is 1.00000\n","Epoch 19, Batch 290: Loss is 0.00195; Accuracy is 1.00000\n","Epoch 19, Batch 300: Loss is 0.00019; Accuracy is 1.00000\n","Epoch 19, Batch 310: Loss is 0.00326; Accuracy is 1.00000\n","Epoch 19, Batch 320: Loss is 0.00305; Accuracy is 1.00000\n","Epoch 19, Batch 330: Loss is 0.25797; Accuracy is 0.66667\n","Epoch 19, Batch 340: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 19, Batch 350: Loss is 0.07066; Accuracy is 1.00000\n","Epoch 19, Batch 360: Loss is 0.06474; Accuracy is 1.00000\n","Epoch 19, Batch 370: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 19, Batch 380: Loss is 0.11524; Accuracy is 1.00000\n","Epoch 19: Average loss is: 0.30981; Average accuracy is: 0.91251\n","Test loss is 3.16134; Accuracy is 0.51875\n","Epoch 20, Batch 0: Loss is 0.00346; Accuracy is 1.00000\n","Epoch 20, Batch 10: Loss is 0.11894; Accuracy is 1.00000\n","Epoch 20, Batch 20: Loss is 0.17331; Accuracy is 1.00000\n","Epoch 20, Batch 30: Loss is 0.00969; Accuracy is 1.00000\n","Epoch 20, Batch 40: Loss is 0.35968; Accuracy is 1.00000\n","Epoch 20, Batch 50: Loss is 0.00991; Accuracy is 1.00000\n","Epoch 20, Batch 60: Loss is 0.08893; Accuracy is 1.00000\n","Epoch 20, Batch 70: Loss is 0.05718; Accuracy is 1.00000\n","Epoch 20, Batch 80: Loss is 0.01967; Accuracy is 1.00000\n","Epoch 20, Batch 90: Loss is 0.19916; Accuracy is 1.00000\n","Epoch 20, Batch 100: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 20, Batch 110: Loss is 0.00050; Accuracy is 1.00000\n","Epoch 20, Batch 120: Loss is 0.03868; Accuracy is 1.00000\n","Epoch 20, Batch 130: Loss is 0.00006; Accuracy is 1.00000\n","Epoch 20, Batch 140: Loss is 0.07959; Accuracy is 1.00000\n","Epoch 20, Batch 150: Loss is 0.31458; Accuracy is 1.00000\n","Epoch 20, Batch 160: Loss is 0.09805; Accuracy is 1.00000\n","Epoch 20, Batch 170: Loss is 0.08072; Accuracy is 1.00000\n","Epoch 20, Batch 180: Loss is 0.00010; Accuracy is 1.00000\n","Epoch 20, Batch 190: Loss is 0.43314; Accuracy is 0.66667\n","Epoch 20, Batch 200: Loss is 0.01669; Accuracy is 1.00000\n","Epoch 20, Batch 210: Loss is 0.32252; Accuracy is 0.66667\n","Epoch 20, Batch 220: Loss is 0.12458; Accuracy is 1.00000\n","Epoch 20, Batch 230: Loss is 0.73388; Accuracy is 0.33333\n","Epoch 20, Batch 240: Loss is 0.00297; Accuracy is 1.00000\n","Epoch 20, Batch 250: Loss is 0.00049; Accuracy is 1.00000\n","Epoch 20, Batch 260: Loss is 1.82886; Accuracy is 0.66667\n","Epoch 20, Batch 270: Loss is 0.00177; Accuracy is 1.00000\n","Epoch 20, Batch 280: Loss is 0.00007; Accuracy is 1.00000\n","Epoch 20, Batch 290: Loss is 0.00019; Accuracy is 1.00000\n","Epoch 20, Batch 300: Loss is 0.06116; Accuracy is 1.00000\n","Epoch 20, Batch 310: Loss is 0.14224; Accuracy is 1.00000\n","Epoch 20, Batch 320: Loss is 0.01222; Accuracy is 1.00000\n","Epoch 20, Batch 330: Loss is 0.03968; Accuracy is 1.00000\n","Epoch 20, Batch 340: Loss is 0.00231; Accuracy is 1.00000\n","Epoch 20, Batch 350: Loss is 0.00122; Accuracy is 1.00000\n","Epoch 20, Batch 360: Loss is 0.15218; Accuracy is 1.00000\n","Epoch 20, Batch 370: Loss is 4.29568; Accuracy is 0.66667\n","Epoch 20, Batch 380: Loss is 0.05674; Accuracy is 1.00000\n","Epoch 20: Average loss is: 0.31833; Average accuracy is: 0.91076\n","Test loss is 3.61711; Accuracy is 0.50625\n","Epoch 21, Batch 0: Loss is 1.21910; Accuracy is 0.66667\n","Epoch 21, Batch 10: Loss is 0.01170; Accuracy is 1.00000\n","Epoch 21, Batch 20: Loss is 0.00063; Accuracy is 1.00000\n","Epoch 21, Batch 30: Loss is 0.00071; Accuracy is 1.00000\n","Epoch 21, Batch 40: Loss is 0.34011; Accuracy is 0.66667\n","Epoch 21, Batch 50: Loss is 0.29796; Accuracy is 0.66667\n","Epoch 21, Batch 60: Loss is 0.13440; Accuracy is 1.00000\n","Epoch 21, Batch 70: Loss is 0.00051; Accuracy is 1.00000\n","Epoch 21, Batch 80: Loss is 0.03183; Accuracy is 1.00000\n","Epoch 21, Batch 90: Loss is 0.02842; Accuracy is 1.00000\n","Epoch 21, Batch 100: Loss is 0.01992; Accuracy is 1.00000\n","Epoch 21, Batch 110: Loss is 0.06633; Accuracy is 1.00000\n","Epoch 21, Batch 120: Loss is 0.04292; Accuracy is 1.00000\n","Epoch 21, Batch 130: Loss is 0.00039; Accuracy is 1.00000\n","Epoch 21, Batch 140: Loss is 0.00024; Accuracy is 1.00000\n","Epoch 21, Batch 150: Loss is 0.00291; Accuracy is 1.00000\n","Epoch 21, Batch 160: Loss is 0.42420; Accuracy is 0.66667\n","Epoch 21, Batch 170: Loss is 0.01002; Accuracy is 1.00000\n","Epoch 21, Batch 180: Loss is 0.00034; Accuracy is 1.00000\n","Epoch 21, Batch 190: Loss is 0.11993; Accuracy is 1.00000\n","Epoch 21, Batch 200: Loss is 0.01476; Accuracy is 1.00000\n","Epoch 21, Batch 210: Loss is 0.00015; Accuracy is 1.00000\n","Epoch 21, Batch 220: Loss is 0.01223; Accuracy is 1.00000\n","Epoch 21, Batch 230: Loss is 1.79007; Accuracy is 0.66667\n","Epoch 21, Batch 240: Loss is 0.23841; Accuracy is 1.00000\n","Epoch 21, Batch 250: Loss is 0.16602; Accuracy is 1.00000\n","Epoch 21, Batch 260: Loss is 1.03961; Accuracy is 0.66667\n","Epoch 21, Batch 270: Loss is 0.99031; Accuracy is 0.66667\n","Epoch 21, Batch 280: Loss is 6.59932; Accuracy is 0.00000\n","Epoch 21, Batch 290: Loss is 4.31560; Accuracy is 0.00000\n","Epoch 21, Batch 300: Loss is 0.20927; Accuracy is 1.00000\n","Epoch 21, Batch 310: Loss is 0.31936; Accuracy is 1.00000\n","Epoch 21, Batch 320: Loss is 0.18027; Accuracy is 1.00000\n","Epoch 21, Batch 330: Loss is 0.11869; Accuracy is 1.00000\n","Epoch 21, Batch 340: Loss is 0.18389; Accuracy is 1.00000\n","Epoch 21, Batch 350: Loss is 0.04474; Accuracy is 1.00000\n","Epoch 21, Batch 360: Loss is 0.15320; Accuracy is 1.00000\n","Epoch 21, Batch 370: Loss is 0.03880; Accuracy is 1.00000\n","Epoch 21, Batch 380: Loss is 0.00214; Accuracy is 1.00000\n","Epoch 21: Average loss is: 0.40587; Average accuracy is: 0.89326\n","Test loss is 3.88350; Accuracy is 0.50625\n","Epoch 22, Batch 0: Loss is 0.24831; Accuracy is 1.00000\n","Epoch 22, Batch 10: Loss is 0.04554; Accuracy is 1.00000\n","Epoch 22, Batch 20: Loss is 0.15958; Accuracy is 1.00000\n","Epoch 22, Batch 30: Loss is 0.00485; Accuracy is 1.00000\n","Epoch 22, Batch 40: Loss is 0.00156; Accuracy is 1.00000\n","Epoch 22, Batch 50: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 22, Batch 60: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 22, Batch 70: Loss is 0.00672; Accuracy is 1.00000\n","Epoch 22, Batch 80: Loss is 0.00052; Accuracy is 1.00000\n","Epoch 22, Batch 90: Loss is 0.00284; Accuracy is 1.00000\n","Epoch 22, Batch 100: Loss is 0.00204; Accuracy is 1.00000\n","Epoch 22, Batch 110: Loss is 0.69923; Accuracy is 0.66667\n","Epoch 22, Batch 120: Loss is 0.02199; Accuracy is 1.00000\n","Epoch 22, Batch 130: Loss is 0.76729; Accuracy is 0.66667\n","Epoch 22, Batch 140: Loss is 0.00709; Accuracy is 1.00000\n","Epoch 22, Batch 150: Loss is 0.00156; Accuracy is 1.00000\n","Epoch 22, Batch 160: Loss is 0.05463; Accuracy is 1.00000\n","Epoch 22, Batch 170: Loss is 0.52102; Accuracy is 0.66667\n","Epoch 22, Batch 180: Loss is 0.00181; Accuracy is 1.00000\n","Epoch 22, Batch 190: Loss is 0.05496; Accuracy is 1.00000\n","Epoch 22, Batch 200: Loss is 0.08470; Accuracy is 1.00000\n","Epoch 22, Batch 210: Loss is 0.01105; Accuracy is 1.00000\n","Epoch 22, Batch 220: Loss is 1.77081; Accuracy is 0.33333\n","Epoch 22, Batch 230: Loss is 0.00011; Accuracy is 1.00000\n","Epoch 22, Batch 240: Loss is 0.02769; Accuracy is 1.00000\n","Epoch 22, Batch 250: Loss is 0.46563; Accuracy is 1.00000\n","Epoch 22, Batch 260: Loss is 0.03056; Accuracy is 1.00000\n","Epoch 22, Batch 270: Loss is 0.00108; Accuracy is 1.00000\n","Epoch 22, Batch 280: Loss is 0.01072; Accuracy is 1.00000\n","Epoch 22, Batch 290: Loss is 1.16243; Accuracy is 0.66667\n","Epoch 22, Batch 300: Loss is 0.00641; Accuracy is 1.00000\n","Epoch 22, Batch 310: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 22, Batch 320: Loss is 1.06644; Accuracy is 0.66667\n","Epoch 22, Batch 330: Loss is 0.29410; Accuracy is 1.00000\n","Epoch 22, Batch 340: Loss is 0.00036; Accuracy is 1.00000\n","Epoch 22, Batch 350: Loss is 0.01433; Accuracy is 1.00000\n","Epoch 22, Batch 360: Loss is 0.20449; Accuracy is 1.00000\n","Epoch 22, Batch 370: Loss is 2.04282; Accuracy is 0.66667\n","Epoch 22, Batch 380: Loss is 0.00161; Accuracy is 1.00000\n","Epoch 22: Average loss is: 0.24480; Average accuracy is: 0.92738\n","Test loss is 2.71144; Accuracy is 0.55000\n","Epoch 23, Batch 0: Loss is 0.04289; Accuracy is 1.00000\n","Epoch 23, Batch 10: Loss is 0.00007; Accuracy is 1.00000\n","Epoch 23, Batch 20: Loss is 0.22434; Accuracy is 1.00000\n","Epoch 23, Batch 30: Loss is 0.00009; Accuracy is 1.00000\n","Epoch 23, Batch 40: Loss is 0.15205; Accuracy is 1.00000\n","Epoch 23, Batch 50: Loss is 0.01133; Accuracy is 1.00000\n","Epoch 23, Batch 60: Loss is 0.12666; Accuracy is 1.00000\n","Epoch 23, Batch 70: Loss is 0.78371; Accuracy is 0.66667\n","Epoch 23, Batch 80: Loss is 0.51911; Accuracy is 0.66667\n","Epoch 23, Batch 90: Loss is 0.00013; Accuracy is 1.00000\n","Epoch 23, Batch 100: Loss is 0.08696; Accuracy is 1.00000\n","Epoch 23, Batch 110: Loss is 0.19146; Accuracy is 1.00000\n","Epoch 23, Batch 120: Loss is 0.59241; Accuracy is 0.66667\n","Epoch 23, Batch 130: Loss is 0.02888; Accuracy is 1.00000\n","Epoch 23, Batch 140: Loss is 0.00185; Accuracy is 1.00000\n","Epoch 23, Batch 150: Loss is 0.00007; Accuracy is 1.00000\n","Epoch 23, Batch 160: Loss is 0.02467; Accuracy is 1.00000\n","Epoch 23, Batch 170: Loss is 0.00018; Accuracy is 1.00000\n","Epoch 23, Batch 180: Loss is 0.02748; Accuracy is 1.00000\n","Epoch 23, Batch 190: Loss is 0.00037; Accuracy is 1.00000\n","Epoch 23, Batch 200: Loss is 0.15755; Accuracy is 1.00000\n","Epoch 23, Batch 210: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 23, Batch 220: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 23, Batch 230: Loss is 0.00011; Accuracy is 1.00000\n","Epoch 23, Batch 240: Loss is 0.00108; Accuracy is 1.00000\n","Epoch 23, Batch 250: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 23, Batch 260: Loss is 0.08387; Accuracy is 1.00000\n","Epoch 23, Batch 270: Loss is 0.83315; Accuracy is 0.66667\n","Epoch 23, Batch 280: Loss is 0.06015; Accuracy is 1.00000\n","Epoch 23, Batch 290: Loss is 0.00321; Accuracy is 1.00000\n","Epoch 23, Batch 300: Loss is 0.27219; Accuracy is 0.66667\n","Epoch 23, Batch 310: Loss is 0.00366; Accuracy is 1.00000\n","Epoch 23, Batch 320: Loss is 0.00152; Accuracy is 1.00000\n","Epoch 23, Batch 330: Loss is 0.51368; Accuracy is 0.66667\n","Epoch 23, Batch 340: Loss is 0.07452; Accuracy is 1.00000\n","Epoch 23, Batch 350: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 23, Batch 360: Loss is 0.00182; Accuracy is 1.00000\n","Epoch 23, Batch 370: Loss is 0.07458; Accuracy is 1.00000\n","Epoch 23, Batch 380: Loss is 0.00065; Accuracy is 1.00000\n","Epoch 23: Average loss is: 0.12710; Average accuracy is: 0.95801\n","Test loss is 3.97921; Accuracy is 0.56250\n","Epoch 24, Batch 0: Loss is 0.00463; Accuracy is 1.00000\n","Epoch 24, Batch 10: Loss is 0.01248; Accuracy is 1.00000\n","Epoch 24, Batch 20: Loss is 0.00014; Accuracy is 1.00000\n","Epoch 24, Batch 30: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 24, Batch 40: Loss is 0.00012; Accuracy is 1.00000\n","Epoch 24, Batch 50: Loss is 0.01976; Accuracy is 1.00000\n","Epoch 24, Batch 60: Loss is 0.00874; Accuracy is 1.00000\n","Epoch 24, Batch 70: Loss is 0.01855; Accuracy is 1.00000\n","Epoch 24, Batch 80: Loss is 0.00130; Accuracy is 1.00000\n","Epoch 24, Batch 90: Loss is 0.00013; Accuracy is 1.00000\n","Epoch 24, Batch 100: Loss is 0.04680; Accuracy is 1.00000\n","Epoch 24, Batch 110: Loss is 0.13875; Accuracy is 1.00000\n","Epoch 24, Batch 120: Loss is 0.01873; Accuracy is 1.00000\n","Epoch 24, Batch 130: Loss is 0.06766; Accuracy is 1.00000\n","Epoch 24, Batch 140: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 24, Batch 150: Loss is 0.77084; Accuracy is 0.66667\n","Epoch 24, Batch 160: Loss is 0.01521; Accuracy is 1.00000\n","Epoch 24, Batch 170: Loss is 0.06038; Accuracy is 1.00000\n","Epoch 24, Batch 180: Loss is 1.73963; Accuracy is 0.66667\n","Epoch 24, Batch 190: Loss is 0.01639; Accuracy is 1.00000\n","Epoch 24, Batch 200: Loss is 0.28260; Accuracy is 1.00000\n","Epoch 24, Batch 210: Loss is 0.33956; Accuracy is 1.00000\n","Epoch 24, Batch 220: Loss is 0.03204; Accuracy is 1.00000\n","Epoch 24, Batch 230: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 24, Batch 240: Loss is 0.03128; Accuracy is 1.00000\n","Epoch 24, Batch 250: Loss is 0.14920; Accuracy is 1.00000\n","Epoch 24, Batch 260: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 24, Batch 270: Loss is 0.65156; Accuracy is 0.66667\n","Epoch 24, Batch 280: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 24, Batch 290: Loss is 0.63883; Accuracy is 0.66667\n","Epoch 24, Batch 300: Loss is 1.88047; Accuracy is 0.66667\n","Epoch 24, Batch 310: Loss is 0.16040; Accuracy is 1.00000\n","Epoch 24, Batch 320: Loss is 0.00742; Accuracy is 1.00000\n","Epoch 24, Batch 330: Loss is 0.02859; Accuracy is 1.00000\n","Epoch 24, Batch 340: Loss is 0.05175; Accuracy is 1.00000\n","Epoch 24, Batch 350: Loss is 1.35228; Accuracy is 0.66667\n","Epoch 24, Batch 360: Loss is 0.02270; Accuracy is 1.00000\n","Epoch 24, Batch 370: Loss is 0.46075; Accuracy is 0.66667\n","Epoch 24, Batch 380: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 24: Average loss is: 0.32445; Average accuracy is: 0.92126\n","Test loss is 2.79625; Accuracy is 0.49375\n","Epoch 25, Batch 0: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 25, Batch 10: Loss is 0.05419; Accuracy is 1.00000\n","Epoch 25, Batch 20: Loss is 0.07398; Accuracy is 1.00000\n","Epoch 25, Batch 30: Loss is 0.00972; Accuracy is 1.00000\n","Epoch 25, Batch 40: Loss is 0.00006; Accuracy is 1.00000\n","Epoch 25, Batch 50: Loss is 1.08451; Accuracy is 0.66667\n","Epoch 25, Batch 60: Loss is 0.28772; Accuracy is 0.66667\n","Epoch 25, Batch 70: Loss is 0.01827; Accuracy is 1.00000\n","Epoch 25, Batch 80: Loss is 0.00017; Accuracy is 1.00000\n","Epoch 25, Batch 90: Loss is 0.00782; Accuracy is 1.00000\n","Epoch 25, Batch 100: Loss is 0.01316; Accuracy is 1.00000\n","Epoch 25, Batch 110: Loss is 0.65444; Accuracy is 0.66667\n","Epoch 25, Batch 120: Loss is 0.00048; Accuracy is 1.00000\n","Epoch 25, Batch 130: Loss is 0.00327; Accuracy is 1.00000\n","Epoch 25, Batch 140: Loss is 0.50504; Accuracy is 0.66667\n","Epoch 25, Batch 150: Loss is 0.82797; Accuracy is 0.66667\n","Epoch 25, Batch 160: Loss is 0.00406; Accuracy is 1.00000\n","Epoch 25, Batch 170: Loss is 0.02901; Accuracy is 1.00000\n","Epoch 25, Batch 180: Loss is 0.00019; Accuracy is 1.00000\n","Epoch 25, Batch 190: Loss is 0.00958; Accuracy is 1.00000\n","Epoch 25, Batch 200: Loss is 2.08768; Accuracy is 0.66667\n","Epoch 25, Batch 210: Loss is 0.94790; Accuracy is 0.66667\n","Epoch 25, Batch 220: Loss is 0.61612; Accuracy is 0.66667\n","Epoch 25, Batch 230: Loss is 0.48515; Accuracy is 0.66667\n","Epoch 25, Batch 240: Loss is 0.17802; Accuracy is 1.00000\n","Epoch 25, Batch 250: Loss is 0.00205; Accuracy is 1.00000\n","Epoch 25, Batch 260: Loss is 0.03770; Accuracy is 1.00000\n","Epoch 25, Batch 270: Loss is 0.09225; Accuracy is 1.00000\n","Epoch 25, Batch 280: Loss is 0.26688; Accuracy is 1.00000\n","Epoch 25, Batch 290: Loss is 0.47537; Accuracy is 0.66667\n","Epoch 25, Batch 300: Loss is 0.00957; Accuracy is 1.00000\n","Epoch 25, Batch 310: Loss is 0.01092; Accuracy is 1.00000\n","Epoch 25, Batch 320: Loss is 0.02943; Accuracy is 1.00000\n","Epoch 25, Batch 330: Loss is 0.00042; Accuracy is 1.00000\n","Epoch 25, Batch 340: Loss is 1.43618; Accuracy is 0.66667\n","Epoch 25, Batch 350: Loss is 0.07057; Accuracy is 1.00000\n","Epoch 25, Batch 360: Loss is 0.18777; Accuracy is 1.00000\n","Epoch 25, Batch 370: Loss is 0.07135; Accuracy is 1.00000\n","Epoch 25, Batch 380: Loss is 0.00098; Accuracy is 1.00000\n","Epoch 25: Average loss is: 0.29263; Average accuracy is: 0.91601\n","Test loss is 2.88829; Accuracy is 0.45937\n","Epoch 26, Batch 0: Loss is 0.08721; Accuracy is 1.00000\n","Epoch 26, Batch 10: Loss is 0.02288; Accuracy is 1.00000\n","Epoch 26, Batch 20: Loss is 0.00590; Accuracy is 1.00000\n","Epoch 26, Batch 30: Loss is 0.02970; Accuracy is 1.00000\n","Epoch 26, Batch 40: Loss is 0.96886; Accuracy is 0.66667\n","Epoch 26, Batch 50: Loss is 0.00516; Accuracy is 1.00000\n","Epoch 26, Batch 60: Loss is 0.00290; Accuracy is 1.00000\n","Epoch 26, Batch 70: Loss is 0.00012; Accuracy is 1.00000\n","Epoch 26, Batch 80: Loss is 1.38053; Accuracy is 0.66667\n","Epoch 26, Batch 90: Loss is 0.00216; Accuracy is 1.00000\n","Epoch 26, Batch 100: Loss is 0.04229; Accuracy is 1.00000\n","Epoch 26, Batch 110: Loss is 0.00384; Accuracy is 1.00000\n","Epoch 26, Batch 120: Loss is 0.00218; Accuracy is 1.00000\n","Epoch 26, Batch 130: Loss is 0.31530; Accuracy is 0.66667\n","Epoch 26, Batch 140: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 26, Batch 150: Loss is 0.10079; Accuracy is 1.00000\n","Epoch 26, Batch 160: Loss is 0.99445; Accuracy is 0.66667\n","Epoch 26, Batch 170: Loss is 0.04073; Accuracy is 1.00000\n","Epoch 26, Batch 180: Loss is 1.56051; Accuracy is 0.66667\n","Epoch 26, Batch 190: Loss is 0.02433; Accuracy is 1.00000\n","Epoch 26, Batch 200: Loss is 0.01507; Accuracy is 1.00000\n","Epoch 26, Batch 210: Loss is 0.02310; Accuracy is 1.00000\n","Epoch 26, Batch 220: Loss is 0.06622; Accuracy is 1.00000\n","Epoch 26, Batch 230: Loss is 0.74016; Accuracy is 0.66667\n","Epoch 26, Batch 240: Loss is 0.14208; Accuracy is 1.00000\n","Epoch 26, Batch 250: Loss is 0.02134; Accuracy is 1.00000\n","Epoch 26, Batch 260: Loss is 0.00434; Accuracy is 1.00000\n","Epoch 26, Batch 270: Loss is 0.00037; Accuracy is 1.00000\n","Epoch 26, Batch 280: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 26, Batch 290: Loss is 0.00783; Accuracy is 1.00000\n","Epoch 26, Batch 300: Loss is 0.26616; Accuracy is 0.66667\n","Epoch 26, Batch 310: Loss is 0.20884; Accuracy is 1.00000\n","Epoch 26, Batch 320: Loss is 0.00016; Accuracy is 1.00000\n","Epoch 26, Batch 330: Loss is 0.03262; Accuracy is 1.00000\n","Epoch 26, Batch 340: Loss is 0.20889; Accuracy is 1.00000\n","Epoch 26, Batch 350: Loss is 0.06545; Accuracy is 1.00000\n","Epoch 26, Batch 360: Loss is 0.11849; Accuracy is 1.00000\n","Epoch 26, Batch 370: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 26, Batch 380: Loss is 0.00105; Accuracy is 1.00000\n","Epoch 26: Average loss is: 0.26592; Average accuracy is: 0.92826\n","Test loss is 2.46985; Accuracy is 0.52812\n","Epoch 27, Batch 0: Loss is 0.00050; Accuracy is 1.00000\n","Epoch 27, Batch 10: Loss is 0.09287; Accuracy is 1.00000\n","Epoch 27, Batch 20: Loss is 0.18579; Accuracy is 1.00000\n","Epoch 27, Batch 30: Loss is 0.03620; Accuracy is 1.00000\n","Epoch 27, Batch 40: Loss is 0.00496; Accuracy is 1.00000\n","Epoch 27, Batch 50: Loss is 0.06459; Accuracy is 1.00000\n","Epoch 27, Batch 60: Loss is 0.00157; Accuracy is 1.00000\n","Epoch 27, Batch 70: Loss is 0.00346; Accuracy is 1.00000\n","Epoch 27, Batch 80: Loss is 0.46781; Accuracy is 0.66667\n","Epoch 27, Batch 90: Loss is 0.00326; Accuracy is 1.00000\n","Epoch 27, Batch 100: Loss is 0.04550; Accuracy is 1.00000\n","Epoch 27, Batch 110: Loss is 0.46700; Accuracy is 0.66667\n","Epoch 27, Batch 120: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 27, Batch 130: Loss is 0.03776; Accuracy is 1.00000\n","Epoch 27, Batch 140: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 27, Batch 150: Loss is 0.00252; Accuracy is 1.00000\n","Epoch 27, Batch 160: Loss is 0.01888; Accuracy is 1.00000\n","Epoch 27, Batch 170: Loss is 1.16893; Accuracy is 0.66667\n","Epoch 27, Batch 180: Loss is 0.00062; Accuracy is 1.00000\n","Epoch 27, Batch 190: Loss is 0.00281; Accuracy is 1.00000\n","Epoch 27, Batch 200: Loss is 0.00407; Accuracy is 1.00000\n","Epoch 27, Batch 210: Loss is 0.00831; Accuracy is 1.00000\n","Epoch 27, Batch 220: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 27, Batch 230: Loss is 0.26252; Accuracy is 1.00000\n","Epoch 27, Batch 240: Loss is 0.44839; Accuracy is 0.66667\n","Epoch 27, Batch 250: Loss is 1.55999; Accuracy is 0.66667\n","Epoch 27, Batch 260: Loss is 0.00043; Accuracy is 1.00000\n","Epoch 27, Batch 270: Loss is 0.02022; Accuracy is 1.00000\n","Epoch 27, Batch 280: Loss is 1.13953; Accuracy is 0.66667\n","Epoch 27, Batch 290: Loss is 0.67040; Accuracy is 0.66667\n","Epoch 27, Batch 300: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 27, Batch 310: Loss is 0.00375; Accuracy is 1.00000\n","Epoch 27, Batch 320: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 27, Batch 330: Loss is 0.02974; Accuracy is 1.00000\n","Epoch 27, Batch 340: Loss is 0.00062; Accuracy is 1.00000\n","Epoch 27, Batch 350: Loss is 3.06885; Accuracy is 0.66667\n","Epoch 27, Batch 360: Loss is 0.08606; Accuracy is 1.00000\n","Epoch 27, Batch 370: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 27, Batch 380: Loss is 0.00538; Accuracy is 1.00000\n","Epoch 27: Average loss is: 0.17174; Average accuracy is: 0.94663\n","Test loss is 2.67642; Accuracy is 0.52812\n","Epoch 28, Batch 0: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 28, Batch 10: Loss is 0.00532; Accuracy is 1.00000\n","Epoch 28, Batch 20: Loss is 0.00339; Accuracy is 1.00000\n","Epoch 28, Batch 30: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 28, Batch 40: Loss is 0.00048; Accuracy is 1.00000\n","Epoch 28, Batch 50: Loss is 0.37556; Accuracy is 0.66667\n","Epoch 28, Batch 60: Loss is 0.00016; Accuracy is 1.00000\n","Epoch 28, Batch 70: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 28, Batch 80: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 28, Batch 90: Loss is 0.02306; Accuracy is 1.00000\n","Epoch 28, Batch 100: Loss is 0.00006; Accuracy is 1.00000\n","Epoch 28, Batch 110: Loss is 0.01748; Accuracy is 1.00000\n","Epoch 28, Batch 120: Loss is 0.02906; Accuracy is 1.00000\n","Epoch 28, Batch 130: Loss is 0.03542; Accuracy is 1.00000\n","Epoch 28, Batch 140: Loss is 0.01694; Accuracy is 1.00000\n","Epoch 28, Batch 150: Loss is 0.00373; Accuracy is 1.00000\n","Epoch 28, Batch 160: Loss is 0.00049; Accuracy is 1.00000\n","Epoch 28, Batch 170: Loss is 0.03222; Accuracy is 1.00000\n","Epoch 28, Batch 180: Loss is 0.00056; Accuracy is 1.00000\n","Epoch 28, Batch 190: Loss is 0.00104; Accuracy is 1.00000\n","Epoch 28, Batch 200: Loss is 0.00085; Accuracy is 1.00000\n","Epoch 28, Batch 210: Loss is 0.09873; Accuracy is 1.00000\n","Epoch 28, Batch 220: Loss is 0.01394; Accuracy is 1.00000\n","Epoch 28, Batch 230: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 28, Batch 240: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 28, Batch 250: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 28, Batch 260: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 28, Batch 270: Loss is 0.00071; Accuracy is 1.00000\n","Epoch 28, Batch 280: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 28, Batch 290: Loss is 0.00032; Accuracy is 1.00000\n","Epoch 28, Batch 300: Loss is 0.12686; Accuracy is 1.00000\n","Epoch 28, Batch 310: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 28, Batch 320: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 28, Batch 330: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 28, Batch 340: Loss is 0.01085; Accuracy is 1.00000\n","Epoch 28, Batch 350: Loss is 0.00088; Accuracy is 1.00000\n","Epoch 28, Batch 360: Loss is 0.00449; Accuracy is 1.00000\n","Epoch 28, Batch 370: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 28, Batch 380: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 28: Average loss is: 0.08292; Average accuracy is: 0.97463\n","Test loss is 3.38730; Accuracy is 0.51562\n","Epoch 29, Batch 0: Loss is 0.00277; Accuracy is 1.00000\n","Epoch 29, Batch 10: Loss is 0.00687; Accuracy is 1.00000\n","Epoch 29, Batch 20: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 29, Batch 30: Loss is 0.00022; Accuracy is 1.00000\n","Epoch 29, Batch 40: Loss is 0.00828; Accuracy is 1.00000\n","Epoch 29, Batch 50: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 29, Batch 60: Loss is 0.00006; Accuracy is 1.00000\n","Epoch 29, Batch 70: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 29, Batch 80: Loss is 2.10863; Accuracy is 0.66667\n","Epoch 29, Batch 90: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 29, Batch 100: Loss is 0.00436; Accuracy is 1.00000\n","Epoch 29, Batch 110: Loss is 0.00041; Accuracy is 1.00000\n","Epoch 29, Batch 120: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 29, Batch 130: Loss is 0.00451; Accuracy is 1.00000\n","Epoch 29, Batch 140: Loss is 0.00008; Accuracy is 1.00000\n","Epoch 29, Batch 150: Loss is 0.35401; Accuracy is 0.66667\n","Epoch 29, Batch 160: Loss is 0.00801; Accuracy is 1.00000\n","Epoch 29, Batch 170: Loss is 0.00023; Accuracy is 1.00000\n","Epoch 29, Batch 180: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 29, Batch 190: Loss is 5.21151; Accuracy is 0.66667\n","Epoch 29, Batch 200: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 29, Batch 210: Loss is 0.00258; Accuracy is 1.00000\n","Epoch 29, Batch 220: Loss is 0.00180; Accuracy is 1.00000\n","Epoch 29, Batch 230: Loss is 0.00016; Accuracy is 1.00000\n","Epoch 29, Batch 240: Loss is 0.00009; Accuracy is 1.00000\n","Epoch 29, Batch 250: Loss is 0.03098; Accuracy is 1.00000\n","Epoch 29, Batch 260: Loss is 0.18498; Accuracy is 1.00000\n","Epoch 29, Batch 270: Loss is 0.06813; Accuracy is 1.00000\n","Epoch 29, Batch 280: Loss is 0.00018; Accuracy is 1.00000\n","Epoch 29, Batch 290: Loss is 0.00006; Accuracy is 1.00000\n","Epoch 29, Batch 300: Loss is 0.00637; Accuracy is 1.00000\n","Epoch 29, Batch 310: Loss is 0.00017; Accuracy is 1.00000\n","Epoch 29, Batch 320: Loss is 1.91625; Accuracy is 0.66667\n","Epoch 29, Batch 330: Loss is 0.42472; Accuracy is 0.66667\n","Epoch 29, Batch 340: Loss is 0.01793; Accuracy is 1.00000\n","Epoch 29, Batch 350: Loss is 0.03719; Accuracy is 1.00000\n","Epoch 29, Batch 360: Loss is 1.91055; Accuracy is 0.66667\n","Epoch 29, Batch 370: Loss is 0.07648; Accuracy is 1.00000\n","Epoch 29, Batch 380: Loss is 0.32480; Accuracy is 0.66667\n","Epoch 29: Average loss is: 0.20622; Average accuracy is: 0.94226\n","Test loss is 3.10825; Accuracy is 0.46875\n","Epoch 30, Batch 0: Loss is 0.78895; Accuracy is 0.66667\n","Epoch 30, Batch 10: Loss is 0.00188; Accuracy is 1.00000\n","Epoch 30, Batch 20: Loss is 0.04522; Accuracy is 1.00000\n","Epoch 30, Batch 30: Loss is 0.00026; Accuracy is 1.00000\n","Epoch 30, Batch 40: Loss is 0.59495; Accuracy is 0.66667\n","Epoch 30, Batch 50: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 30, Batch 60: Loss is 0.01228; Accuracy is 1.00000\n","Epoch 30, Batch 70: Loss is 0.00286; Accuracy is 1.00000\n","Epoch 30, Batch 80: Loss is 4.72074; Accuracy is 0.66667\n","Epoch 30, Batch 90: Loss is 0.00235; Accuracy is 1.00000\n","Epoch 30, Batch 100: Loss is 0.01342; Accuracy is 1.00000\n","Epoch 30, Batch 110: Loss is 0.00070; Accuracy is 1.00000\n","Epoch 30, Batch 120: Loss is 0.00309; Accuracy is 1.00000\n","Epoch 30, Batch 130: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 30, Batch 140: Loss is 0.57377; Accuracy is 0.66667\n","Epoch 30, Batch 150: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 30, Batch 160: Loss is 0.00033; Accuracy is 1.00000\n","Epoch 30, Batch 170: Loss is 0.00538; Accuracy is 1.00000\n","Epoch 30, Batch 180: Loss is 0.00245; Accuracy is 1.00000\n","Epoch 30, Batch 190: Loss is 0.07132; Accuracy is 1.00000\n","Epoch 30, Batch 200: Loss is 0.00034; Accuracy is 1.00000\n","Epoch 30, Batch 210: Loss is 0.03269; Accuracy is 1.00000\n","Epoch 30, Batch 220: Loss is 0.00136; Accuracy is 1.00000\n","Epoch 30, Batch 230: Loss is 0.00006; Accuracy is 1.00000\n","Epoch 30, Batch 240: Loss is 0.76965; Accuracy is 0.66667\n","Epoch 30, Batch 250: Loss is 0.01835; Accuracy is 1.00000\n","Epoch 30, Batch 260: Loss is 0.01145; Accuracy is 1.00000\n","Epoch 30, Batch 270: Loss is 0.00012; Accuracy is 1.00000\n","Epoch 30, Batch 280: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 30, Batch 290: Loss is 1.19834; Accuracy is 0.33333\n","Epoch 30, Batch 300: Loss is 0.01406; Accuracy is 1.00000\n","Epoch 30, Batch 310: Loss is 3.82434; Accuracy is 0.66667\n","Epoch 30, Batch 320: Loss is 0.00076; Accuracy is 1.00000\n","Epoch 30, Batch 330: Loss is 0.01665; Accuracy is 1.00000\n","Epoch 30, Batch 340: Loss is 0.00053; Accuracy is 1.00000\n","Epoch 30, Batch 350: Loss is 0.22585; Accuracy is 1.00000\n","Epoch 30, Batch 360: Loss is 0.00120; Accuracy is 1.00000\n","Epoch 30, Batch 370: Loss is 0.14470; Accuracy is 1.00000\n","Epoch 30, Batch 380: Loss is 0.01861; Accuracy is 1.00000\n","Epoch 30: Average loss is: 0.20705; Average accuracy is: 0.94313\n","Test loss is 3.72896; Accuracy is 0.45625\n","Epoch 31, Batch 0: Loss is 0.00457; Accuracy is 1.00000\n","Epoch 31, Batch 10: Loss is 0.00066; Accuracy is 1.00000\n","Epoch 31, Batch 20: Loss is 0.18969; Accuracy is 1.00000\n","Epoch 31, Batch 30: Loss is 0.00351; Accuracy is 1.00000\n","Epoch 31, Batch 40: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 31, Batch 50: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 31, Batch 60: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 31, Batch 70: Loss is 0.00337; Accuracy is 1.00000\n","Epoch 31, Batch 80: Loss is 0.09954; Accuracy is 1.00000\n","Epoch 31, Batch 90: Loss is 0.02858; Accuracy is 1.00000\n","Epoch 31, Batch 100: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 31, Batch 110: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 31, Batch 120: Loss is 0.00940; Accuracy is 1.00000\n","Epoch 31, Batch 130: Loss is 0.21582; Accuracy is 1.00000\n","Epoch 31, Batch 140: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 31, Batch 150: Loss is 0.26078; Accuracy is 1.00000\n","Epoch 31, Batch 160: Loss is 0.01336; Accuracy is 1.00000\n","Epoch 31, Batch 170: Loss is 0.49986; Accuracy is 0.66667\n","Epoch 31, Batch 180: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 31, Batch 190: Loss is 0.00250; Accuracy is 1.00000\n","Epoch 31, Batch 200: Loss is 0.00124; Accuracy is 1.00000\n","Epoch 31, Batch 210: Loss is 0.00007; Accuracy is 1.00000\n","Epoch 31, Batch 220: Loss is 0.00483; Accuracy is 1.00000\n","Epoch 31, Batch 230: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 31, Batch 240: Loss is 0.00031; Accuracy is 1.00000\n","Epoch 31, Batch 250: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 31, Batch 260: Loss is 0.00053; Accuracy is 1.00000\n","Epoch 31, Batch 270: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 31, Batch 280: Loss is 0.00044; Accuracy is 1.00000\n","Epoch 31, Batch 290: Loss is 0.00507; Accuracy is 1.00000\n","Epoch 31, Batch 300: Loss is 0.00300; Accuracy is 1.00000\n","Epoch 31, Batch 310: Loss is 0.00012; Accuracy is 1.00000\n","Epoch 31, Batch 320: Loss is 0.00551; Accuracy is 1.00000\n","Epoch 31, Batch 330: Loss is 3.02904; Accuracy is 0.66667\n","Epoch 31, Batch 340: Loss is 0.45953; Accuracy is 0.66667\n","Epoch 31, Batch 350: Loss is 0.01558; Accuracy is 1.00000\n","Epoch 31, Batch 360: Loss is 0.00914; Accuracy is 1.00000\n","Epoch 31, Batch 370: Loss is 0.01355; Accuracy is 1.00000\n","Epoch 31, Batch 380: Loss is 0.01928; Accuracy is 1.00000\n","Epoch 31: Average loss is: 0.13856; Average accuracy is: 0.95888\n","Test loss is 2.94035; Accuracy is 0.49062\n","Epoch 32, Batch 0: Loss is 0.00370; Accuracy is 1.00000\n","Epoch 32, Batch 10: Loss is 1.87824; Accuracy is 0.66667\n","Epoch 32, Batch 20: Loss is 0.02098; Accuracy is 1.00000\n","Epoch 32, Batch 30: Loss is 0.00190; Accuracy is 1.00000\n","Epoch 32, Batch 40: Loss is 0.50447; Accuracy is 0.66667\n","Epoch 32, Batch 50: Loss is 0.00623; Accuracy is 1.00000\n","Epoch 32, Batch 60: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 32, Batch 70: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 32, Batch 80: Loss is 0.10837; Accuracy is 1.00000\n","Epoch 32, Batch 90: Loss is 0.00026; Accuracy is 1.00000\n","Epoch 32, Batch 100: Loss is 0.00023; Accuracy is 1.00000\n","Epoch 32, Batch 110: Loss is 0.00087; Accuracy is 1.00000\n","Epoch 32, Batch 120: Loss is 0.00275; Accuracy is 1.00000\n","Epoch 32, Batch 130: Loss is 0.00070; Accuracy is 1.00000\n","Epoch 32, Batch 140: Loss is 0.00023; Accuracy is 1.00000\n","Epoch 32, Batch 150: Loss is 0.23499; Accuracy is 1.00000\n","Epoch 32, Batch 160: Loss is 2.00100; Accuracy is 0.66667\n","Epoch 32, Batch 170: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 32, Batch 180: Loss is 0.09226; Accuracy is 1.00000\n","Epoch 32, Batch 190: Loss is 0.75987; Accuracy is 0.66667\n","Epoch 32, Batch 200: Loss is 0.71731; Accuracy is 0.66667\n","Epoch 32, Batch 210: Loss is 0.16185; Accuracy is 1.00000\n","Epoch 32, Batch 220: Loss is 0.42008; Accuracy is 0.66667\n","Epoch 32, Batch 230: Loss is 0.01558; Accuracy is 1.00000\n","Epoch 32, Batch 240: Loss is 0.00273; Accuracy is 1.00000\n","Epoch 32, Batch 250: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 32, Batch 260: Loss is 0.01364; Accuracy is 1.00000\n","Epoch 32, Batch 270: Loss is 0.00115; Accuracy is 1.00000\n","Epoch 32, Batch 280: Loss is 0.02013; Accuracy is 1.00000\n","Epoch 32, Batch 290: Loss is 0.41312; Accuracy is 0.66667\n","Epoch 32, Batch 300: Loss is 0.00038; Accuracy is 1.00000\n","Epoch 32, Batch 310: Loss is 0.02043; Accuracy is 1.00000\n","Epoch 32, Batch 320: Loss is 0.00200; Accuracy is 1.00000\n","Epoch 32, Batch 330: Loss is 0.00095; Accuracy is 1.00000\n","Epoch 32, Batch 340: Loss is 0.83643; Accuracy is 0.66667\n","Epoch 32, Batch 350: Loss is 0.00294; Accuracy is 1.00000\n","Epoch 32, Batch 360: Loss is 0.00365; Accuracy is 1.00000\n","Epoch 32, Batch 370: Loss is 0.03131; Accuracy is 1.00000\n","Epoch 32, Batch 380: Loss is 0.00196; Accuracy is 1.00000\n","Epoch 32: Average loss is: 0.15319; Average accuracy is: 0.95976\n","Test loss is 4.27162; Accuracy is 0.47500\n","Epoch 33, Batch 0: Loss is 0.00169; Accuracy is 1.00000\n","Epoch 33, Batch 10: Loss is 0.00156; Accuracy is 1.00000\n","Epoch 33, Batch 20: Loss is 1.40639; Accuracy is 0.66667\n","Epoch 33, Batch 30: Loss is 0.01167; Accuracy is 1.00000\n","Epoch 33, Batch 40: Loss is 0.00049; Accuracy is 1.00000\n","Epoch 33, Batch 50: Loss is 0.29329; Accuracy is 0.66667\n","Epoch 33, Batch 60: Loss is 0.00105; Accuracy is 1.00000\n","Epoch 33, Batch 70: Loss is 0.00134; Accuracy is 1.00000\n","Epoch 33, Batch 80: Loss is 0.00226; Accuracy is 1.00000\n","Epoch 33, Batch 90: Loss is 0.13001; Accuracy is 1.00000\n","Epoch 33, Batch 100: Loss is 0.00523; Accuracy is 1.00000\n","Epoch 33, Batch 110: Loss is 0.20163; Accuracy is 1.00000\n","Epoch 33, Batch 120: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 33, Batch 130: Loss is 0.00055; Accuracy is 1.00000\n","Epoch 33, Batch 140: Loss is 0.00042; Accuracy is 1.00000\n","Epoch 33, Batch 150: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 33, Batch 160: Loss is 0.00049; Accuracy is 1.00000\n","Epoch 33, Batch 170: Loss is 0.00052; Accuracy is 1.00000\n","Epoch 33, Batch 180: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 33, Batch 190: Loss is 0.03655; Accuracy is 1.00000\n","Epoch 33, Batch 200: Loss is 1.89685; Accuracy is 0.66667\n","Epoch 33, Batch 210: Loss is 0.04215; Accuracy is 1.00000\n","Epoch 33, Batch 220: Loss is 0.06925; Accuracy is 1.00000\n","Epoch 33, Batch 230: Loss is 0.03035; Accuracy is 1.00000\n","Epoch 33, Batch 240: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 33, Batch 250: Loss is 0.00835; Accuracy is 1.00000\n","Epoch 33, Batch 260: Loss is 0.00007; Accuracy is 1.00000\n","Epoch 33, Batch 270: Loss is 0.00129; Accuracy is 1.00000\n","Epoch 33, Batch 280: Loss is 0.21198; Accuracy is 1.00000\n","Epoch 33, Batch 290: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 33, Batch 300: Loss is 0.00185; Accuracy is 1.00000\n","Epoch 33, Batch 310: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 33, Batch 320: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 33, Batch 330: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 33, Batch 340: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 33, Batch 350: Loss is 0.00099; Accuracy is 1.00000\n","Epoch 33, Batch 360: Loss is 0.00008; Accuracy is 1.00000\n","Epoch 33, Batch 370: Loss is 0.30794; Accuracy is 0.66667\n","Epoch 33, Batch 380: Loss is 0.00009; Accuracy is 1.00000\n","Epoch 33: Average loss is: 0.11895; Average accuracy is: 0.97113\n","Test loss is 3.79120; Accuracy is 0.55000\n","Epoch 34, Batch 0: Loss is 0.00110; Accuracy is 1.00000\n","Epoch 34, Batch 10: Loss is 0.03128; Accuracy is 1.00000\n","Epoch 34, Batch 20: Loss is 0.00304; Accuracy is 1.00000\n","Epoch 34, Batch 30: Loss is 0.01909; Accuracy is 1.00000\n","Epoch 34, Batch 40: Loss is 0.00999; Accuracy is 1.00000\n","Epoch 34, Batch 50: Loss is 0.04268; Accuracy is 1.00000\n","Epoch 34, Batch 60: Loss is 0.00688; Accuracy is 1.00000\n","Epoch 34, Batch 70: Loss is 0.39493; Accuracy is 0.66667\n","Epoch 34, Batch 80: Loss is 0.02720; Accuracy is 1.00000\n","Epoch 34, Batch 90: Loss is 0.56953; Accuracy is 0.66667\n","Epoch 34, Batch 100: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 34, Batch 110: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 34, Batch 120: Loss is 0.03850; Accuracy is 1.00000\n","Epoch 34, Batch 130: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 34, Batch 140: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 34, Batch 150: Loss is 0.07083; Accuracy is 1.00000\n","Epoch 34, Batch 160: Loss is 0.00086; Accuracy is 1.00000\n","Epoch 34, Batch 170: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 34, Batch 180: Loss is 0.00031; Accuracy is 1.00000\n","Epoch 34, Batch 190: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 34, Batch 200: Loss is 0.00396; Accuracy is 1.00000\n","Epoch 34, Batch 210: Loss is 0.00107; Accuracy is 1.00000\n","Epoch 34, Batch 220: Loss is 0.77166; Accuracy is 0.66667\n","Epoch 34, Batch 230: Loss is 1.70895; Accuracy is 0.66667\n","Epoch 34, Batch 240: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 34, Batch 250: Loss is 1.25374; Accuracy is 0.66667\n","Epoch 34, Batch 260: Loss is 0.01173; Accuracy is 1.00000\n","Epoch 34, Batch 270: Loss is 0.04955; Accuracy is 1.00000\n","Epoch 34, Batch 280: Loss is 0.77453; Accuracy is 0.66667\n","Epoch 34, Batch 290: Loss is 0.66776; Accuracy is 0.66667\n","Epoch 34, Batch 300: Loss is 0.00026; Accuracy is 1.00000\n","Epoch 34, Batch 310: Loss is 0.59998; Accuracy is 0.66667\n","Epoch 34, Batch 320: Loss is 0.00067; Accuracy is 1.00000\n","Epoch 34, Batch 330: Loss is 1.90932; Accuracy is 0.33333\n","Epoch 34, Batch 340: Loss is 0.42906; Accuracy is 0.66667\n","Epoch 34, Batch 350: Loss is 0.03636; Accuracy is 1.00000\n","Epoch 34, Batch 360: Loss is 0.53358; Accuracy is 0.66667\n","Epoch 34, Batch 370: Loss is 0.02140; Accuracy is 1.00000\n","Epoch 34, Batch 380: Loss is 0.00029; Accuracy is 1.00000\n","Epoch 34: Average loss is: 0.54794; Average accuracy is: 0.88889\n","Test loss is 3.53753; Accuracy is 0.45000\n","Epoch 35, Batch 0: Loss is 0.24999; Accuracy is 1.00000\n","Epoch 35, Batch 10: Loss is 0.00157; Accuracy is 1.00000\n","Epoch 35, Batch 20: Loss is 0.05835; Accuracy is 1.00000\n","Epoch 35, Batch 30: Loss is 0.00011; Accuracy is 1.00000\n","Epoch 35, Batch 40: Loss is 0.05101; Accuracy is 1.00000\n","Epoch 35, Batch 50: Loss is 0.02220; Accuracy is 1.00000\n","Epoch 35, Batch 60: Loss is 1.62018; Accuracy is 0.66667\n","Epoch 35, Batch 70: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 35, Batch 80: Loss is 0.01095; Accuracy is 1.00000\n","Epoch 35, Batch 90: Loss is 0.00429; Accuracy is 1.00000\n","Epoch 35, Batch 100: Loss is 0.00851; Accuracy is 1.00000\n","Epoch 35, Batch 110: Loss is 0.01738; Accuracy is 1.00000\n","Epoch 35, Batch 120: Loss is 0.01008; Accuracy is 1.00000\n","Epoch 35, Batch 130: Loss is 0.00070; Accuracy is 1.00000\n","Epoch 35, Batch 140: Loss is 0.29243; Accuracy is 0.66667\n","Epoch 35, Batch 150: Loss is 0.00709; Accuracy is 1.00000\n","Epoch 35, Batch 160: Loss is 0.01180; Accuracy is 1.00000\n","Epoch 35, Batch 170: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 35, Batch 180: Loss is 0.00018; Accuracy is 1.00000\n","Epoch 35, Batch 190: Loss is 0.08953; Accuracy is 1.00000\n","Epoch 35, Batch 200: Loss is 0.40950; Accuracy is 0.66667\n","Epoch 35, Batch 210: Loss is 0.24747; Accuracy is 1.00000\n","Epoch 35, Batch 220: Loss is 0.01230; Accuracy is 1.00000\n","Epoch 35, Batch 230: Loss is 0.48337; Accuracy is 0.66667\n","Epoch 35, Batch 240: Loss is 0.03141; Accuracy is 1.00000\n","Epoch 35, Batch 250: Loss is 0.00371; Accuracy is 1.00000\n","Epoch 35, Batch 260: Loss is 0.08663; Accuracy is 1.00000\n","Epoch 35, Batch 270: Loss is 0.00831; Accuracy is 1.00000\n","Epoch 35, Batch 280: Loss is 0.03280; Accuracy is 1.00000\n","Epoch 35, Batch 290: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 35, Batch 300: Loss is 0.08517; Accuracy is 1.00000\n","Epoch 35, Batch 310: Loss is 0.01609; Accuracy is 1.00000\n","Epoch 35, Batch 320: Loss is 0.02963; Accuracy is 1.00000\n","Epoch 35, Batch 330: Loss is 0.00019; Accuracy is 1.00000\n","Epoch 35, Batch 340: Loss is 0.06481; Accuracy is 1.00000\n","Epoch 35, Batch 350: Loss is 0.13161; Accuracy is 1.00000\n","Epoch 35, Batch 360: Loss is 0.00084; Accuracy is 1.00000\n","Epoch 35, Batch 370: Loss is 0.00533; Accuracy is 1.00000\n","Epoch 35, Batch 380: Loss is 0.00044; Accuracy is 1.00000\n","Epoch 35: Average loss is: 0.16337; Average accuracy is: 0.95801\n","Test loss is 3.15581; Accuracy is 0.49062\n","Epoch 36, Batch 0: Loss is 0.00089; Accuracy is 1.00000\n","Epoch 36, Batch 10: Loss is 0.00076; Accuracy is 1.00000\n","Epoch 36, Batch 20: Loss is 0.00394; Accuracy is 1.00000\n","Epoch 36, Batch 30: Loss is 0.00102; Accuracy is 1.00000\n","Epoch 36, Batch 40: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 36, Batch 50: Loss is 0.00823; Accuracy is 1.00000\n","Epoch 36, Batch 60: Loss is 0.02648; Accuracy is 1.00000\n","Epoch 36, Batch 70: Loss is 0.00332; Accuracy is 1.00000\n","Epoch 36, Batch 80: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 36, Batch 90: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 36, Batch 100: Loss is 0.01311; Accuracy is 1.00000\n","Epoch 36, Batch 110: Loss is 0.00206; Accuracy is 1.00000\n","Epoch 36, Batch 120: Loss is 0.00033; Accuracy is 1.00000\n","Epoch 36, Batch 130: Loss is 0.00015; Accuracy is 1.00000\n","Epoch 36, Batch 140: Loss is 0.01433; Accuracy is 1.00000\n","Epoch 36, Batch 150: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 36, Batch 160: Loss is 0.00369; Accuracy is 1.00000\n","Epoch 36, Batch 170: Loss is 0.39054; Accuracy is 0.66667\n","Epoch 36, Batch 180: Loss is 0.01511; Accuracy is 1.00000\n","Epoch 36, Batch 190: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 36, Batch 200: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 36, Batch 210: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 36, Batch 220: Loss is 0.00045; Accuracy is 1.00000\n","Epoch 36, Batch 230: Loss is 0.00293; Accuracy is 1.00000\n","Epoch 36, Batch 240: Loss is 0.00006; Accuracy is 1.00000\n","Epoch 36, Batch 250: Loss is 0.00012; Accuracy is 1.00000\n","Epoch 36, Batch 260: Loss is 0.03608; Accuracy is 1.00000\n","Epoch 36, Batch 270: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 36, Batch 280: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 36, Batch 290: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 36, Batch 300: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 36, Batch 310: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 36, Batch 320: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 36, Batch 330: Loss is 0.00072; Accuracy is 1.00000\n","Epoch 36, Batch 340: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 36, Batch 350: Loss is 0.61495; Accuracy is 0.66667\n","Epoch 36, Batch 360: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 36, Batch 370: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 36, Batch 380: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 36: Average loss is: 0.07074; Average accuracy is: 0.97725\n","Test loss is 3.97441; Accuracy is 0.53438\n","Epoch 37, Batch 0: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 37, Batch 10: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 37, Batch 20: Loss is 0.00260; Accuracy is 1.00000\n","Epoch 37, Batch 30: Loss is 0.00014; Accuracy is 1.00000\n","Epoch 37, Batch 40: Loss is 0.02374; Accuracy is 1.00000\n","Epoch 37, Batch 50: Loss is 0.00022; Accuracy is 1.00000\n","Epoch 37, Batch 60: Loss is 1.34750; Accuracy is 0.66667\n","Epoch 37, Batch 70: Loss is 0.01352; Accuracy is 1.00000\n","Epoch 37, Batch 80: Loss is 0.00295; Accuracy is 1.00000\n","Epoch 37, Batch 90: Loss is 0.27637; Accuracy is 1.00000\n","Epoch 37, Batch 100: Loss is 0.00821; Accuracy is 1.00000\n","Epoch 37, Batch 110: Loss is 1.49901; Accuracy is 0.66667\n","Epoch 37, Batch 120: Loss is 0.00033; Accuracy is 1.00000\n","Epoch 37, Batch 130: Loss is 0.11382; Accuracy is 1.00000\n","Epoch 37, Batch 140: Loss is 0.01463; Accuracy is 1.00000\n","Epoch 37, Batch 150: Loss is 0.01541; Accuracy is 1.00000\n","Epoch 37, Batch 160: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 37, Batch 170: Loss is 0.00096; Accuracy is 1.00000\n","Epoch 37, Batch 180: Loss is 0.16844; Accuracy is 1.00000\n","Epoch 37, Batch 190: Loss is 0.00295; Accuracy is 1.00000\n","Epoch 37, Batch 200: Loss is 0.00350; Accuracy is 1.00000\n","Epoch 37, Batch 210: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 37, Batch 220: Loss is 0.05664; Accuracy is 1.00000\n","Epoch 37, Batch 230: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 37, Batch 240: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 37, Batch 250: Loss is 0.00102; Accuracy is 1.00000\n","Epoch 37, Batch 260: Loss is 1.80962; Accuracy is 0.66667\n","Epoch 37, Batch 270: Loss is 0.12309; Accuracy is 1.00000\n","Epoch 37, Batch 280: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 37, Batch 290: Loss is 0.62726; Accuracy is 1.00000\n","Epoch 37, Batch 300: Loss is 0.00023; Accuracy is 1.00000\n","Epoch 37, Batch 310: Loss is 0.00284; Accuracy is 1.00000\n","Epoch 37, Batch 320: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 37, Batch 330: Loss is 0.00234; Accuracy is 1.00000\n","Epoch 37, Batch 340: Loss is 0.05824; Accuracy is 1.00000\n","Epoch 37, Batch 350: Loss is 1.26051; Accuracy is 0.66667\n","Epoch 37, Batch 360: Loss is 0.00236; Accuracy is 1.00000\n","Epoch 37, Batch 370: Loss is 0.05690; Accuracy is 1.00000\n","Epoch 37, Batch 380: Loss is 0.00161; Accuracy is 1.00000\n","Epoch 37: Average loss is: 0.32809; Average accuracy is: 0.92476\n","Test loss is 5.58685; Accuracy is 0.43438\n","Epoch 38, Batch 0: Loss is 0.20039; Accuracy is 1.00000\n","Epoch 38, Batch 10: Loss is 0.01700; Accuracy is 1.00000\n","Epoch 38, Batch 20: Loss is 0.01845; Accuracy is 1.00000\n","Epoch 38, Batch 30: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 38, Batch 40: Loss is 0.04543; Accuracy is 1.00000\n","Epoch 38, Batch 50: Loss is 0.14129; Accuracy is 1.00000\n","Epoch 38, Batch 60: Loss is 0.07140; Accuracy is 1.00000\n","Epoch 38, Batch 70: Loss is 0.00012; Accuracy is 1.00000\n","Epoch 38, Batch 80: Loss is 0.24009; Accuracy is 1.00000\n","Epoch 38, Batch 90: Loss is 0.00257; Accuracy is 1.00000\n","Epoch 38, Batch 100: Loss is 1.62186; Accuracy is 0.66667\n","Epoch 38, Batch 110: Loss is 0.00201; Accuracy is 1.00000\n","Epoch 38, Batch 120: Loss is 0.00092; Accuracy is 1.00000\n","Epoch 38, Batch 130: Loss is 0.00102; Accuracy is 1.00000\n","Epoch 38, Batch 140: Loss is 0.28463; Accuracy is 1.00000\n","Epoch 38, Batch 150: Loss is 0.00201; Accuracy is 1.00000\n","Epoch 38, Batch 160: Loss is 0.00887; Accuracy is 1.00000\n","Epoch 38, Batch 170: Loss is 0.02807; Accuracy is 1.00000\n","Epoch 38, Batch 180: Loss is 0.00012; Accuracy is 1.00000\n","Epoch 38, Batch 190: Loss is 0.00260; Accuracy is 1.00000\n","Epoch 38, Batch 200: Loss is 0.51881; Accuracy is 0.66667\n","Epoch 38, Batch 210: Loss is 0.13616; Accuracy is 1.00000\n","Epoch 38, Batch 220: Loss is 0.00566; Accuracy is 1.00000\n","Epoch 38, Batch 230: Loss is 0.04241; Accuracy is 1.00000\n","Epoch 38, Batch 240: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 38, Batch 250: Loss is 0.00222; Accuracy is 1.00000\n","Epoch 38, Batch 260: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 38, Batch 270: Loss is 0.00120; Accuracy is 1.00000\n","Epoch 38, Batch 280: Loss is 0.00246; Accuracy is 1.00000\n","Epoch 38, Batch 290: Loss is 0.00078; Accuracy is 1.00000\n","Epoch 38, Batch 300: Loss is 0.00019; Accuracy is 1.00000\n","Epoch 38, Batch 310: Loss is 0.00024; Accuracy is 1.00000\n","Epoch 38, Batch 320: Loss is 0.00156; Accuracy is 1.00000\n","Epoch 38, Batch 330: Loss is 0.23387; Accuracy is 0.66667\n","Epoch 38, Batch 340: Loss is 0.00149; Accuracy is 1.00000\n","Epoch 38, Batch 350: Loss is 0.00011; Accuracy is 1.00000\n","Epoch 38, Batch 360: Loss is 0.01745; Accuracy is 1.00000\n","Epoch 38, Batch 370: Loss is 0.00020; Accuracy is 1.00000\n","Epoch 38, Batch 380: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 38: Average loss is: 0.12356; Average accuracy is: 0.97375\n","Test loss is 3.96033; Accuracy is 0.50313\n","Epoch 39, Batch 0: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 10: Loss is 0.05640; Accuracy is 1.00000\n","Epoch 39, Batch 20: Loss is 0.00770; Accuracy is 1.00000\n","Epoch 39, Batch 30: Loss is 0.00267; Accuracy is 1.00000\n","Epoch 39, Batch 40: Loss is 0.02203; Accuracy is 1.00000\n","Epoch 39, Batch 50: Loss is 0.00101; Accuracy is 1.00000\n","Epoch 39, Batch 60: Loss is 0.00056; Accuracy is 1.00000\n","Epoch 39, Batch 70: Loss is 0.00357; Accuracy is 1.00000\n","Epoch 39, Batch 80: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 90: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 100: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 110: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 120: Loss is 0.01157; Accuracy is 1.00000\n","Epoch 39, Batch 130: Loss is 0.00062; Accuracy is 1.00000\n","Epoch 39, Batch 140: Loss is 0.00184; Accuracy is 1.00000\n","Epoch 39, Batch 150: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 39, Batch 160: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 170: Loss is 0.00012; Accuracy is 1.00000\n","Epoch 39, Batch 180: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 190: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 200: Loss is 0.00254; Accuracy is 1.00000\n","Epoch 39, Batch 210: Loss is 0.06048; Accuracy is 1.00000\n","Epoch 39, Batch 220: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 230: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 240: Loss is 0.00208; Accuracy is 1.00000\n","Epoch 39, Batch 250: Loss is 0.00205; Accuracy is 1.00000\n","Epoch 39, Batch 260: Loss is 0.00058; Accuracy is 1.00000\n","Epoch 39, Batch 270: Loss is 0.00016; Accuracy is 1.00000\n","Epoch 39, Batch 280: Loss is 0.18208; Accuracy is 1.00000\n","Epoch 39, Batch 290: Loss is 0.80110; Accuracy is 0.33333\n","Epoch 39, Batch 300: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 39, Batch 310: Loss is 0.78292; Accuracy is 0.66667\n","Epoch 39, Batch 320: Loss is 1.29361; Accuracy is 0.66667\n","Epoch 39, Batch 330: Loss is 0.03604; Accuracy is 1.00000\n","Epoch 39, Batch 340: Loss is 0.00085; Accuracy is 1.00000\n","Epoch 39, Batch 350: Loss is 0.04189; Accuracy is 1.00000\n","Epoch 39, Batch 360: Loss is 0.00116; Accuracy is 1.00000\n","Epoch 39, Batch 370: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 39, Batch 380: Loss is 0.23461; Accuracy is 1.00000\n","Epoch 39: Average loss is: 0.11436; Average accuracy is: 0.96850\n","Test loss is 4.48962; Accuracy is 0.47188\n","Epoch 40, Batch 0: Loss is 0.00057; Accuracy is 1.00000\n","Epoch 40, Batch 10: Loss is 0.47227; Accuracy is 0.66667\n","Epoch 40, Batch 20: Loss is 0.00059; Accuracy is 1.00000\n","Epoch 40, Batch 30: Loss is 0.50610; Accuracy is 0.66667\n","Epoch 40, Batch 40: Loss is 0.03546; Accuracy is 1.00000\n","Epoch 40, Batch 50: Loss is 0.77193; Accuracy is 0.66667\n","Epoch 40, Batch 60: Loss is 1.02882; Accuracy is 0.66667\n","Epoch 40, Batch 70: Loss is 0.00299; Accuracy is 1.00000\n","Epoch 40, Batch 80: Loss is 0.44873; Accuracy is 0.66667\n","Epoch 40, Batch 90: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 40, Batch 100: Loss is 0.00023; Accuracy is 1.00000\n","Epoch 40, Batch 110: Loss is 0.00261; Accuracy is 1.00000\n","Epoch 40, Batch 120: Loss is 0.00018; Accuracy is 1.00000\n","Epoch 40, Batch 130: Loss is 0.00035; Accuracy is 1.00000\n","Epoch 40, Batch 140: Loss is 0.00050; Accuracy is 1.00000\n","Epoch 40, Batch 150: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 40, Batch 160: Loss is 0.02444; Accuracy is 1.00000\n","Epoch 40, Batch 170: Loss is 0.00011; Accuracy is 1.00000\n","Epoch 40, Batch 180: Loss is 0.00074; Accuracy is 1.00000\n","Epoch 40, Batch 190: Loss is 0.01725; Accuracy is 1.00000\n","Epoch 40, Batch 200: Loss is 0.14503; Accuracy is 1.00000\n","Epoch 40, Batch 210: Loss is 0.00030; Accuracy is 1.00000\n","Epoch 40, Batch 220: Loss is 0.02889; Accuracy is 1.00000\n","Epoch 40, Batch 230: Loss is 0.00668; Accuracy is 1.00000\n","Epoch 40, Batch 240: Loss is 0.00094; Accuracy is 1.00000\n","Epoch 40, Batch 250: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 40, Batch 260: Loss is 0.09838; Accuracy is 1.00000\n","Epoch 40, Batch 270: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 40, Batch 280: Loss is 0.00160; Accuracy is 1.00000\n","Epoch 40, Batch 290: Loss is 0.05039; Accuracy is 1.00000\n","Epoch 40, Batch 300: Loss is 0.00065; Accuracy is 1.00000\n","Epoch 40, Batch 310: Loss is 0.00086; Accuracy is 1.00000\n","Epoch 40, Batch 320: Loss is 0.49162; Accuracy is 0.66667\n","Epoch 40, Batch 330: Loss is 0.13639; Accuracy is 1.00000\n","Epoch 40, Batch 340: Loss is 0.00017; Accuracy is 1.00000\n","Epoch 40, Batch 350: Loss is 0.03672; Accuracy is 1.00000\n","Epoch 40, Batch 360: Loss is 0.00147; Accuracy is 1.00000\n","Epoch 40, Batch 370: Loss is 0.12866; Accuracy is 1.00000\n","Epoch 40, Batch 380: Loss is 0.00017; Accuracy is 1.00000\n","Epoch 40: Average loss is: 0.14694; Average accuracy is: 0.95713\n","Test loss is 3.29444; Accuracy is 0.53125\n","Epoch 41, Batch 0: Loss is 0.02493; Accuracy is 1.00000\n","Epoch 41, Batch 10: Loss is 0.00006; Accuracy is 1.00000\n","Epoch 41, Batch 20: Loss is 0.00148; Accuracy is 1.00000\n","Epoch 41, Batch 30: Loss is 0.00164; Accuracy is 1.00000\n","Epoch 41, Batch 40: Loss is 0.00184; Accuracy is 1.00000\n","Epoch 41, Batch 50: Loss is 0.00207; Accuracy is 1.00000\n","Epoch 41, Batch 60: Loss is 0.00021; Accuracy is 1.00000\n","Epoch 41, Batch 70: Loss is 0.17345; Accuracy is 1.00000\n","Epoch 41, Batch 80: Loss is 0.19202; Accuracy is 1.00000\n","Epoch 41, Batch 90: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 41, Batch 100: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 41, Batch 110: Loss is 0.00360; Accuracy is 1.00000\n","Epoch 41, Batch 120: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 41, Batch 130: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 41, Batch 140: Loss is 0.01035; Accuracy is 1.00000\n","Epoch 41, Batch 150: Loss is 0.00063; Accuracy is 1.00000\n","Epoch 41, Batch 160: Loss is 0.11284; Accuracy is 1.00000\n","Epoch 41, Batch 170: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 41, Batch 180: Loss is 0.00064; Accuracy is 1.00000\n","Epoch 41, Batch 190: Loss is 0.04087; Accuracy is 1.00000\n","Epoch 41, Batch 200: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 41, Batch 210: Loss is 0.12402; Accuracy is 1.00000\n","Epoch 41, Batch 220: Loss is 0.06868; Accuracy is 1.00000\n","Epoch 41, Batch 230: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 41, Batch 240: Loss is 0.19943; Accuracy is 1.00000\n","Epoch 41, Batch 250: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 41, Batch 260: Loss is 1.63909; Accuracy is 0.66667\n","Epoch 41, Batch 270: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 41, Batch 280: Loss is 0.00308; Accuracy is 1.00000\n","Epoch 41, Batch 290: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 41, Batch 300: Loss is 0.00007; Accuracy is 1.00000\n","Epoch 41, Batch 310: Loss is 0.00018; Accuracy is 1.00000\n","Epoch 41, Batch 320: Loss is 2.48025; Accuracy is 0.66667\n","Epoch 41, Batch 330: Loss is 0.00125; Accuracy is 1.00000\n","Epoch 41, Batch 340: Loss is 0.00032; Accuracy is 1.00000\n","Epoch 41, Batch 350: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 41, Batch 360: Loss is 1.73872; Accuracy is 0.33333\n","Epoch 41, Batch 370: Loss is 0.00070; Accuracy is 1.00000\n","Epoch 41, Batch 380: Loss is 0.00031; Accuracy is 1.00000\n","Epoch 41: Average loss is: 0.09509; Average accuracy is: 0.97550\n","Test loss is 5.78548; Accuracy is 0.40000\n","Epoch 42, Batch 0: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 42, Batch 10: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 42, Batch 20: Loss is 0.02819; Accuracy is 1.00000\n","Epoch 42, Batch 30: Loss is 5.09140; Accuracy is 0.33333\n","Epoch 42, Batch 40: Loss is 0.95820; Accuracy is 0.66667\n","Epoch 42, Batch 50: Loss is 0.00008; Accuracy is 1.00000\n","Epoch 42, Batch 60: Loss is 2.11368; Accuracy is 0.66667\n","Epoch 42, Batch 70: Loss is 0.04102; Accuracy is 1.00000\n","Epoch 42, Batch 80: Loss is 0.61510; Accuracy is 0.66667\n","Epoch 42, Batch 90: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 42, Batch 100: Loss is 1.66194; Accuracy is 0.66667\n","Epoch 42, Batch 110: Loss is 0.03307; Accuracy is 1.00000\n","Epoch 42, Batch 120: Loss is 0.00056; Accuracy is 1.00000\n","Epoch 42, Batch 130: Loss is 0.17183; Accuracy is 1.00000\n","Epoch 42, Batch 140: Loss is 0.00023; Accuracy is 1.00000\n","Epoch 42, Batch 150: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 42, Batch 160: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 42, Batch 170: Loss is 0.02727; Accuracy is 1.00000\n","Epoch 42, Batch 180: Loss is 0.00046; Accuracy is 1.00000\n","Epoch 42, Batch 190: Loss is 0.01646; Accuracy is 1.00000\n","Epoch 42, Batch 200: Loss is 0.00257; Accuracy is 1.00000\n","Epoch 42, Batch 210: Loss is 0.03013; Accuracy is 1.00000\n","Epoch 42, Batch 220: Loss is 0.00056; Accuracy is 1.00000\n","Epoch 42, Batch 230: Loss is 0.00478; Accuracy is 1.00000\n","Epoch 42, Batch 240: Loss is 0.04446; Accuracy is 1.00000\n","Epoch 42, Batch 250: Loss is 0.00021; Accuracy is 1.00000\n","Epoch 42, Batch 260: Loss is 0.45551; Accuracy is 0.66667\n","Epoch 42, Batch 270: Loss is 0.01433; Accuracy is 1.00000\n","Epoch 42, Batch 280: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 42, Batch 290: Loss is 0.24420; Accuracy is 1.00000\n","Epoch 42, Batch 300: Loss is 0.00802; Accuracy is 1.00000\n","Epoch 42, Batch 310: Loss is 0.00084; Accuracy is 1.00000\n","Epoch 42, Batch 320: Loss is 6.29708; Accuracy is 0.66667\n","Epoch 42, Batch 330: Loss is 2.49887; Accuracy is 0.33333\n","Epoch 42, Batch 340: Loss is 0.00158; Accuracy is 1.00000\n","Epoch 42, Batch 350: Loss is 1.77785; Accuracy is 0.33333\n","Epoch 42, Batch 360: Loss is 0.36098; Accuracy is 1.00000\n","Epoch 42, Batch 370: Loss is 0.07428; Accuracy is 1.00000\n","Epoch 42, Batch 380: Loss is 1.04058; Accuracy is 0.66667\n","Epoch 42: Average loss is: 0.84555; Average accuracy is: 0.87052\n","Test loss is 2.53969; Accuracy is 0.42500\n","Epoch 43, Batch 0: Loss is 0.00719; Accuracy is 1.00000\n","Epoch 43, Batch 10: Loss is 0.02227; Accuracy is 1.00000\n","Epoch 43, Batch 20: Loss is 0.10885; Accuracy is 1.00000\n","Epoch 43, Batch 30: Loss is 0.00040; Accuracy is 1.00000\n","Epoch 43, Batch 40: Loss is 0.00771; Accuracy is 1.00000\n","Epoch 43, Batch 50: Loss is 0.58893; Accuracy is 0.66667\n","Epoch 43, Batch 60: Loss is 0.43991; Accuracy is 1.00000\n","Epoch 43, Batch 70: Loss is 0.00040; Accuracy is 1.00000\n","Epoch 43, Batch 80: Loss is 0.60731; Accuracy is 0.66667\n","Epoch 43, Batch 90: Loss is 0.00698; Accuracy is 1.00000\n","Epoch 43, Batch 100: Loss is 0.00199; Accuracy is 1.00000\n","Epoch 43, Batch 110: Loss is 0.05427; Accuracy is 1.00000\n","Epoch 43, Batch 120: Loss is 0.00485; Accuracy is 1.00000\n","Epoch 43, Batch 130: Loss is 0.02401; Accuracy is 1.00000\n","Epoch 43, Batch 140: Loss is 0.67245; Accuracy is 0.66667\n","Epoch 43, Batch 150: Loss is 0.14993; Accuracy is 1.00000\n","Epoch 43, Batch 160: Loss is 0.00034; Accuracy is 1.00000\n","Epoch 43, Batch 170: Loss is 0.10268; Accuracy is 1.00000\n","Epoch 43, Batch 180: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 43, Batch 190: Loss is 0.32345; Accuracy is 1.00000\n","Epoch 43, Batch 200: Loss is 0.00010; Accuracy is 1.00000\n","Epoch 43, Batch 210: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 43, Batch 220: Loss is 0.87278; Accuracy is 0.66667\n","Epoch 43, Batch 230: Loss is 0.07377; Accuracy is 1.00000\n","Epoch 43, Batch 240: Loss is 0.06646; Accuracy is 1.00000\n","Epoch 43, Batch 250: Loss is 0.58886; Accuracy is 0.66667\n","Epoch 43, Batch 260: Loss is 0.02945; Accuracy is 1.00000\n","Epoch 43, Batch 270: Loss is 0.19835; Accuracy is 1.00000\n","Epoch 43, Batch 280: Loss is 0.00315; Accuracy is 1.00000\n","Epoch 43, Batch 290: Loss is 0.13657; Accuracy is 1.00000\n","Epoch 43, Batch 300: Loss is 0.00131; Accuracy is 1.00000\n","Epoch 43, Batch 310: Loss is 0.00009; Accuracy is 1.00000\n","Epoch 43, Batch 320: Loss is 0.32788; Accuracy is 0.66667\n","Epoch 43, Batch 330: Loss is 0.01887; Accuracy is 1.00000\n","Epoch 43, Batch 340: Loss is 0.12619; Accuracy is 1.00000\n","Epoch 43, Batch 350: Loss is 0.01499; Accuracy is 1.00000\n","Epoch 43, Batch 360: Loss is 0.00042; Accuracy is 1.00000\n","Epoch 43, Batch 370: Loss is 0.09928; Accuracy is 1.00000\n","Epoch 43, Batch 380: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 43: Average loss is: 0.21685; Average accuracy is: 0.93351\n","Test loss is 4.23715; Accuracy is 0.50000\n","Epoch 44, Batch 0: Loss is 0.00023; Accuracy is 1.00000\n","Epoch 44, Batch 10: Loss is 0.00008; Accuracy is 1.00000\n","Epoch 44, Batch 20: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 44, Batch 30: Loss is 0.00716; Accuracy is 1.00000\n","Epoch 44, Batch 40: Loss is 0.00135; Accuracy is 1.00000\n","Epoch 44, Batch 50: Loss is 0.10127; Accuracy is 1.00000\n","Epoch 44, Batch 60: Loss is 1.23446; Accuracy is 0.66667\n","Epoch 44, Batch 70: Loss is 0.02118; Accuracy is 1.00000\n","Epoch 44, Batch 80: Loss is 0.39613; Accuracy is 0.66667\n","Epoch 44, Batch 90: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 44, Batch 100: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 44, Batch 110: Loss is 0.00011; Accuracy is 1.00000\n","Epoch 44, Batch 120: Loss is 0.31598; Accuracy is 0.66667\n","Epoch 44, Batch 130: Loss is 0.00214; Accuracy is 1.00000\n","Epoch 44, Batch 140: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 44, Batch 150: Loss is 0.02738; Accuracy is 1.00000\n","Epoch 44, Batch 160: Loss is 0.12936; Accuracy is 1.00000\n","Epoch 44, Batch 170: Loss is 1.43035; Accuracy is 0.66667\n","Epoch 44, Batch 180: Loss is 0.00029; Accuracy is 1.00000\n","Epoch 44, Batch 190: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 44, Batch 200: Loss is 0.15129; Accuracy is 1.00000\n","Epoch 44, Batch 210: Loss is 0.00020; Accuracy is 1.00000\n","Epoch 44, Batch 220: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 44, Batch 230: Loss is 0.00377; Accuracy is 1.00000\n","Epoch 44, Batch 240: Loss is 0.48009; Accuracy is 0.66667\n","Epoch 44, Batch 250: Loss is 0.00040; Accuracy is 1.00000\n","Epoch 44, Batch 260: Loss is 0.00227; Accuracy is 1.00000\n","Epoch 44, Batch 270: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 44, Batch 280: Loss is 0.00675; Accuracy is 1.00000\n","Epoch 44, Batch 290: Loss is 0.09582; Accuracy is 1.00000\n","Epoch 44, Batch 300: Loss is 0.10702; Accuracy is 1.00000\n","Epoch 44, Batch 310: Loss is 0.00026; Accuracy is 1.00000\n","Epoch 44, Batch 320: Loss is 2.16530; Accuracy is 0.66667\n","Epoch 44, Batch 330: Loss is 0.00714; Accuracy is 1.00000\n","Epoch 44, Batch 340: Loss is 0.04399; Accuracy is 1.00000\n","Epoch 44, Batch 350: Loss is 0.06442; Accuracy is 1.00000\n","Epoch 44, Batch 360: Loss is 0.00015; Accuracy is 1.00000\n","Epoch 44, Batch 370: Loss is 0.02162; Accuracy is 1.00000\n","Epoch 44, Batch 380: Loss is 0.04382; Accuracy is 1.00000\n","Epoch 44: Average loss is: 0.17104; Average accuracy is: 0.95626\n","Test loss is 3.21135; Accuracy is 0.54375\n","Epoch 45, Batch 0: Loss is 0.01617; Accuracy is 1.00000\n","Epoch 45, Batch 10: Loss is 0.22078; Accuracy is 1.00000\n","Epoch 45, Batch 20: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 45, Batch 30: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 45, Batch 40: Loss is 0.00062; Accuracy is 1.00000\n","Epoch 45, Batch 50: Loss is 0.00238; Accuracy is 1.00000\n","Epoch 45, Batch 60: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 45, Batch 70: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 45, Batch 80: Loss is 0.83111; Accuracy is 0.66667\n","Epoch 45, Batch 90: Loss is 0.56017; Accuracy is 0.66667\n","Epoch 45, Batch 100: Loss is 0.00022; Accuracy is 1.00000\n","Epoch 45, Batch 110: Loss is 0.04080; Accuracy is 1.00000\n","Epoch 45, Batch 120: Loss is 0.00117; Accuracy is 1.00000\n","Epoch 45, Batch 130: Loss is 0.00878; Accuracy is 1.00000\n","Epoch 45, Batch 140: Loss is 0.00039; Accuracy is 1.00000\n","Epoch 45, Batch 150: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 45, Batch 160: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 45, Batch 170: Loss is 0.50091; Accuracy is 0.66667\n","Epoch 45, Batch 180: Loss is 0.00053; Accuracy is 1.00000\n","Epoch 45, Batch 190: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 45, Batch 200: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 45, Batch 210: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 45, Batch 220: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 45, Batch 230: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 45, Batch 240: Loss is 0.73490; Accuracy is 0.66667\n","Epoch 45, Batch 250: Loss is 0.00058; Accuracy is 1.00000\n","Epoch 45, Batch 260: Loss is 0.00023; Accuracy is 1.00000\n","Epoch 45, Batch 270: Loss is 0.01878; Accuracy is 1.00000\n","Epoch 45, Batch 280: Loss is 0.00022; Accuracy is 1.00000\n","Epoch 45, Batch 290: Loss is 0.73570; Accuracy is 0.66667\n","Epoch 45, Batch 300: Loss is 0.02393; Accuracy is 1.00000\n","Epoch 45, Batch 310: Loss is 1.20033; Accuracy is 0.66667\n","Epoch 45, Batch 320: Loss is 0.91743; Accuracy is 0.33333\n","Epoch 45, Batch 330: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 45, Batch 340: Loss is 0.00349; Accuracy is 1.00000\n","Epoch 45, Batch 350: Loss is 0.00012; Accuracy is 1.00000\n","Epoch 45, Batch 360: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 45, Batch 370: Loss is 0.00074; Accuracy is 1.00000\n","Epoch 45, Batch 380: Loss is 0.00064; Accuracy is 1.00000\n","Epoch 45: Average loss is: 0.06057; Average accuracy is: 0.97900\n","Test loss is 5.06420; Accuracy is 0.51562\n","Epoch 46, Batch 0: Loss is 0.00050; Accuracy is 1.00000\n","Epoch 46, Batch 10: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 46, Batch 20: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 30: Loss is 0.02022; Accuracy is 1.00000\n","Epoch 46, Batch 40: Loss is 0.00465; Accuracy is 1.00000\n","Epoch 46, Batch 50: Loss is 0.00598; Accuracy is 1.00000\n","Epoch 46, Batch 60: Loss is 0.00018; Accuracy is 1.00000\n","Epoch 46, Batch 70: Loss is 0.00145; Accuracy is 1.00000\n","Epoch 46, Batch 80: Loss is 0.00103; Accuracy is 1.00000\n","Epoch 46, Batch 90: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 46, Batch 100: Loss is 0.00016; Accuracy is 1.00000\n","Epoch 46, Batch 110: Loss is 0.00013; Accuracy is 1.00000\n","Epoch 46, Batch 120: Loss is 0.00022; Accuracy is 1.00000\n","Epoch 46, Batch 130: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 140: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 150: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 160: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 170: Loss is 0.00220; Accuracy is 1.00000\n","Epoch 46, Batch 180: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 190: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 200: Loss is 0.00094; Accuracy is 1.00000\n","Epoch 46, Batch 210: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 220: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 46, Batch 230: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 46, Batch 240: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 46, Batch 250: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 46, Batch 260: Loss is 0.00070; Accuracy is 1.00000\n","Epoch 46, Batch 270: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 46, Batch 280: Loss is 0.00009; Accuracy is 1.00000\n","Epoch 46, Batch 290: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 300: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 310: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 320: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 46, Batch 330: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 46, Batch 340: Loss is 0.00024; Accuracy is 1.00000\n","Epoch 46, Batch 350: Loss is 0.00018; Accuracy is 1.00000\n","Epoch 46, Batch 360: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 370: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 46, Batch 380: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 46: Average loss is: 0.01323; Average accuracy is: 0.99738\n","Test loss is 4.77359; Accuracy is 0.52500\n","Epoch 47, Batch 0: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 10: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 20: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 30: Loss is 0.00007; Accuracy is 1.00000\n","Epoch 47, Batch 40: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 47, Batch 50: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 47, Batch 60: Loss is 0.00008; Accuracy is 1.00000\n","Epoch 47, Batch 70: Loss is 0.00005; Accuracy is 1.00000\n","Epoch 47, Batch 80: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 90: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 100: Loss is 0.00425; Accuracy is 1.00000\n","Epoch 47, Batch 110: Loss is 0.00028; Accuracy is 1.00000\n","Epoch 47, Batch 120: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 130: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 140: Loss is 0.92147; Accuracy is 0.66667\n","Epoch 47, Batch 150: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 160: Loss is 0.00107; Accuracy is 1.00000\n","Epoch 47, Batch 170: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 180: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 190: Loss is 0.01232; Accuracy is 1.00000\n","Epoch 47, Batch 200: Loss is 1.56162; Accuracy is 0.66667\n","Epoch 47, Batch 210: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 220: Loss is 0.00006; Accuracy is 1.00000\n","Epoch 47, Batch 230: Loss is 0.20237; Accuracy is 1.00000\n","Epoch 47, Batch 240: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 47, Batch 250: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 47, Batch 260: Loss is 0.00028; Accuracy is 1.00000\n","Epoch 47, Batch 270: Loss is 0.00022; Accuracy is 1.00000\n","Epoch 47, Batch 280: Loss is 3.00288; Accuracy is 0.66667\n","Epoch 47, Batch 290: Loss is 0.00223; Accuracy is 1.00000\n","Epoch 47, Batch 300: Loss is 0.05073; Accuracy is 1.00000\n","Epoch 47, Batch 310: Loss is 0.00054; Accuracy is 1.00000\n","Epoch 47, Batch 320: Loss is 0.00142; Accuracy is 1.00000\n","Epoch 47, Batch 330: Loss is 0.42874; Accuracy is 0.66667\n","Epoch 47, Batch 340: Loss is 0.03961; Accuracy is 1.00000\n","Epoch 47, Batch 350: Loss is 0.77687; Accuracy is 0.66667\n","Epoch 47, Batch 360: Loss is 0.00611; Accuracy is 1.00000\n","Epoch 47, Batch 370: Loss is 0.98040; Accuracy is 0.66667\n","Epoch 47, Batch 380: Loss is 0.00869; Accuracy is 1.00000\n","Epoch 47: Average loss is: 0.24187; Average accuracy is: 0.93788\n","Test loss is 3.34515; Accuracy is 0.48750\n","Epoch 48, Batch 0: Loss is 0.02491; Accuracy is 1.00000\n","Epoch 48, Batch 10: Loss is 0.00284; Accuracy is 1.00000\n","Epoch 48, Batch 20: Loss is 0.00013; Accuracy is 1.00000\n","Epoch 48, Batch 30: Loss is 0.00285; Accuracy is 1.00000\n","Epoch 48, Batch 40: Loss is 0.01240; Accuracy is 1.00000\n","Epoch 48, Batch 50: Loss is 0.00021; Accuracy is 1.00000\n","Epoch 48, Batch 60: Loss is 0.01409; Accuracy is 1.00000\n","Epoch 48, Batch 70: Loss is 0.00472; Accuracy is 1.00000\n","Epoch 48, Batch 80: Loss is 0.00553; Accuracy is 1.00000\n","Epoch 48, Batch 90: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 48, Batch 100: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 48, Batch 110: Loss is 0.00161; Accuracy is 1.00000\n","Epoch 48, Batch 120: Loss is 1.52385; Accuracy is 0.66667\n","Epoch 48, Batch 130: Loss is 0.00035; Accuracy is 1.00000\n","Epoch 48, Batch 140: Loss is 0.00609; Accuracy is 1.00000\n","Epoch 48, Batch 150: Loss is 0.15671; Accuracy is 1.00000\n","Epoch 48, Batch 160: Loss is 0.03607; Accuracy is 1.00000\n","Epoch 48, Batch 170: Loss is 0.08790; Accuracy is 1.00000\n","Epoch 48, Batch 180: Loss is 0.00022; Accuracy is 1.00000\n","Epoch 48, Batch 190: Loss is 0.01514; Accuracy is 1.00000\n","Epoch 48, Batch 200: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 48, Batch 210: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 48, Batch 220: Loss is 0.00629; Accuracy is 1.00000\n","Epoch 48, Batch 230: Loss is 0.00750; Accuracy is 1.00000\n","Epoch 48, Batch 240: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 48, Batch 250: Loss is 0.00602; Accuracy is 1.00000\n","Epoch 48, Batch 260: Loss is 0.00018; Accuracy is 1.00000\n","Epoch 48, Batch 270: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 48, Batch 280: Loss is 0.00057; Accuracy is 1.00000\n","Epoch 48, Batch 290: Loss is 0.00007; Accuracy is 1.00000\n","Epoch 48, Batch 300: Loss is 0.32806; Accuracy is 0.66667\n","Epoch 48, Batch 310: Loss is 0.03001; Accuracy is 1.00000\n","Epoch 48, Batch 320: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 48, Batch 330: Loss is 0.00008; Accuracy is 1.00000\n","Epoch 48, Batch 340: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 48, Batch 350: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 48, Batch 360: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 48, Batch 370: Loss is 0.00009; Accuracy is 1.00000\n","Epoch 48, Batch 380: Loss is 0.13276; Accuracy is 1.00000\n","Epoch 48: Average loss is: 0.11440; Average accuracy is: 0.96850\n","Test loss is 5.77422; Accuracy is 0.50000\n","Epoch 49, Batch 0: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 49, Batch 10: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 49, Batch 20: Loss is 2.57283; Accuracy is 0.66667\n","Epoch 49, Batch 30: Loss is 0.01360; Accuracy is 1.00000\n","Epoch 49, Batch 40: Loss is 0.00233; Accuracy is 1.00000\n","Epoch 49, Batch 50: Loss is 0.57706; Accuracy is 0.66667\n","Epoch 49, Batch 60: Loss is 0.02605; Accuracy is 1.00000\n","Epoch 49, Batch 70: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 49, Batch 80: Loss is 0.14121; Accuracy is 1.00000\n","Epoch 49, Batch 90: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 49, Batch 100: Loss is 0.00257; Accuracy is 1.00000\n","Epoch 49, Batch 110: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 49, Batch 120: Loss is 0.23572; Accuracy is 0.66667\n","Epoch 49, Batch 130: Loss is 0.00017; Accuracy is 1.00000\n","Epoch 49, Batch 140: Loss is 0.00225; Accuracy is 1.00000\n","Epoch 49, Batch 150: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 49, Batch 160: Loss is 2.31676; Accuracy is 0.33333\n","Epoch 49, Batch 170: Loss is 0.01537; Accuracy is 1.00000\n","Epoch 49, Batch 180: Loss is 0.00002; Accuracy is 1.00000\n","Epoch 49, Batch 190: Loss is 0.04671; Accuracy is 1.00000\n","Epoch 49, Batch 200: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 49, Batch 210: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 49, Batch 220: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 49, Batch 230: Loss is 0.39337; Accuracy is 0.66667\n","Epoch 49, Batch 240: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 49, Batch 250: Loss is 0.67603; Accuracy is 0.66667\n","Epoch 49, Batch 260: Loss is 0.00266; Accuracy is 1.00000\n","Epoch 49, Batch 270: Loss is 0.24330; Accuracy is 0.66667\n","Epoch 49, Batch 280: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 49, Batch 290: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 49, Batch 300: Loss is 0.00019; Accuracy is 1.00000\n","Epoch 49, Batch 310: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 49, Batch 320: Loss is 0.00048; Accuracy is 1.00000\n","Epoch 49, Batch 330: Loss is 0.00853; Accuracy is 1.00000\n","Epoch 49, Batch 340: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 49, Batch 350: Loss is 0.29827; Accuracy is 1.00000\n","Epoch 49, Batch 360: Loss is 0.00031; Accuracy is 1.00000\n","Epoch 49, Batch 370: Loss is 0.70108; Accuracy is 0.66667\n","Epoch 49, Batch 380: Loss is 0.08365; Accuracy is 1.00000\n","Epoch 49: Average loss is: 0.26439; Average accuracy is: 0.93963\n","Test loss is 3.64687; Accuracy is 0.45000\n","Epoch 50, Batch 0: Loss is 0.00305; Accuracy is 1.00000\n","Epoch 50, Batch 10: Loss is 0.00089; Accuracy is 1.00000\n","Epoch 50, Batch 20: Loss is 0.78379; Accuracy is 0.66667\n","Epoch 50, Batch 30: Loss is 1.50666; Accuracy is 0.66667\n","Epoch 50, Batch 40: Loss is 0.00007; Accuracy is 1.00000\n","Epoch 50, Batch 50: Loss is 0.38688; Accuracy is 0.66667\n","Epoch 50, Batch 60: Loss is 0.03005; Accuracy is 1.00000\n","Epoch 50, Batch 70: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 50, Batch 80: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 50, Batch 90: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 50, Batch 100: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 50, Batch 110: Loss is 0.00001; Accuracy is 1.00000\n","Epoch 50, Batch 120: Loss is 0.00026; Accuracy is 1.00000\n","Epoch 50, Batch 130: Loss is 0.03009; Accuracy is 1.00000\n","Epoch 50, Batch 140: Loss is 0.00008; Accuracy is 1.00000\n","Epoch 50, Batch 150: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 50, Batch 160: Loss is 0.00149; Accuracy is 1.00000\n","Epoch 50, Batch 170: Loss is 0.52683; Accuracy is 0.66667\n","Epoch 50, Batch 180: Loss is 0.00004; Accuracy is 1.00000\n","Epoch 50, Batch 190: Loss is 0.00003; Accuracy is 1.00000\n","Epoch 50, Batch 200: Loss is 0.00556; Accuracy is 1.00000\n","Epoch 50, Batch 210: Loss is 0.97231; Accuracy is 0.66667\n","Epoch 50, Batch 220: Loss is 0.00904; Accuracy is 1.00000\n","Epoch 50, Batch 230: Loss is 0.02846; Accuracy is 1.00000\n","Epoch 50, Batch 240: Loss is 0.00399; Accuracy is 1.00000\n","Epoch 50, Batch 250: Loss is 0.00026; Accuracy is 1.00000\n","Epoch 50, Batch 260: Loss is 0.00085; Accuracy is 1.00000\n","Epoch 50, Batch 270: Loss is 0.00000; Accuracy is 1.00000\n","Epoch 50, Batch 280: Loss is 1.08155; Accuracy is 0.66667\n","Epoch 50, Batch 290: Loss is 0.00034; Accuracy is 1.00000\n","Epoch 50, Batch 300: Loss is 2.90904; Accuracy is 0.66667\n","Epoch 50, Batch 310: Loss is 0.80328; Accuracy is 0.66667\n","Epoch 50, Batch 320: Loss is 0.00275; Accuracy is 1.00000\n","Epoch 50, Batch 330: Loss is 0.00235; Accuracy is 1.00000\n","Epoch 50, Batch 340: Loss is 0.00115; Accuracy is 1.00000\n","Epoch 50, Batch 350: Loss is 0.24134; Accuracy is 0.66667\n","Epoch 50, Batch 360: Loss is 0.03994; Accuracy is 1.00000\n","Epoch 50, Batch 370: Loss is 0.00212; Accuracy is 1.00000\n","Epoch 50, Batch 380: Loss is 0.00745; Accuracy is 1.00000\n","Epoch 50: Average loss is: 0.19276; Average accuracy is: 0.95363\n","Test loss is 4.44514; Accuracy is 0.47813\n"]}],"source":["for epoch in range(EPOCH_NUM):\n","    # train\n","    correct_epoch = 0\n","    loss_epoch = 0\n","    net.train()\n","\n","    for i, batch in enumerate(train_video_dataloader):\n","        batch_clips = batch['clips']\n","        batch_labels = batch['labels']\n","        batch_clips = batch_clips.cuda()\n","        batch_labels = batch_labels.cuda()\n","\n","        logits = net(batch_clips)\n","\n","        loss = F.cross_entropy(logits, batch_labels)\n","        correct = (torch.argmax(logits, 1) == batch_labels).sum()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss_epoch += loss\n","        correct_epoch += correct\n","\n","        if i % 10 == 0:\n","            print('Epoch %d, Batch %d: Loss is %.5f; Accuracy is %.5f'%(epoch+1, i, loss, correct/batch_clips.shape[0]))\n","\n","    print('Epoch %d: Average loss is: %.5f; Average accuracy is: %.5f'%(epoch+1, loss_epoch / len(train_video_dataloader),\n","                                                                                correct_epoch / len(train_video_dataset)))\n","\n","    # test\n","    correct_epoch = 0\n","    loss_epoch = 0\n","    net.eval()\n","\n","    with torch.no_grad():\n","        for i, batch in enumerate(test_video_dataloader):\n","            batch_clips = batch['clips']\n","            batch_labels = batch['labels']\n","            batch_clips = batch_clips.cuda()\n","            batch_labels = batch_labels.cuda()\n","\n","            logits = net(batch_clips)\n","\n","            loss = F.cross_entropy(logits, batch_labels)\n","            correct = (torch.argmax(logits, 1) == batch_labels).sum()\n","\n","            loss_epoch += loss\n","            correct_epoch += correct\n","\n","    print('Test loss is %.5f; Accuracy is %.5f'%(loss_epoch / len(test_video_dataloader),\n","                                                                                correct_epoch / len(test_video_dataset)))\n"]},{"cell_type":"markdown","metadata":{"id":"sbsBK-hft_ma"},"source":["###"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9 (default, Nov 25 2022, 14:10:45) \n[GCC 8.4.0]"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"colab":{"provenance":[{"file_id":"https://github.com/lhb987/SAMSUNG_AI_action_recognition/blob/colab/2_C3D_nonlocal/train.ipynb","timestamp":1689913920396}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}